{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"day-4-fine-tuning-a-custom-model.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":11348509,"datasetId":7099621,"databundleVersionId":11775928}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{"id":"b6e13eef3f5d"}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"cellView":"form","id":"d6597b11df14","jupyter":{"source_hidden":true},"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:23:51.956005Z","iopub.execute_input":"2025-04-10T05:23:51.956650Z","iopub.status.idle":"2025-04-10T05:23:51.962088Z","shell.execute_reply.started":"2025-04-10T05:23:51.956592Z","shell.execute_reply":"2025-04-10T05:23:51.961193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Day 4 - Fine tuning a custom model\n\nWelcome back to the Kaggle 5-day Generative AI course!\n\nIn this notebook you will use the Gemini API to fine-tune a custom, task-specific model. Fine-tuning can be used for a variety of tasks from classic NLP problems like entity extraction or summarisation, to creative tasks like stylised generation. You will fine-tune a model to classify the category a piece of text (a newsgroup post) into the category it belongs to (the newsgroup name).\n\nThis codelab walks you tuning a model with the API. [AI Studio](https://aistudio.google.com/app/tune) also supports creating new tuned models directly in the web UI, allowing you to quickly create and monitor models using data from Google Sheets, Drive or your own files.\n\n**Note**: We recommend doing this codelab first today. There may be a period of waiting while the model tunes, so if you start with this one, you can try the other codelab while you wait.","metadata":{"id":"4KDIFPAL2EnL"}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab  # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"id":"9wafTyEH1_xF","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:23:51.964055Z","iopub.execute_input":"2025-04-10T05:23:51.964799Z","iopub.status.idle":"2025-04-10T05:24:00.040561Z","shell.execute_reply.started":"2025-04-10T05:23:51.964765Z","shell.execute_reply":"2025-04-10T05:24:00.039241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\ngenai.__version__","metadata":{"id":"T0CBG9xL2PvT","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.041977Z","iopub.execute_input":"2025-04-10T05:24:00.042261Z","iopub.status.idle":"2025-04-10T05:24:00.048071Z","shell.execute_reply.started":"2025-04-10T05:24:00.042237Z","shell.execute_reply":"2025-04-10T05:24:00.047177Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Set up your API key\n\nTo run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n\nIf you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n\nTo make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook.","metadata":{"id":"P4bYX2T72ScK"}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"id":"VuJPY3GK2SLZ","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.050312Z","iopub.execute_input":"2025-04-10T05:24:00.050613Z","iopub.status.idle":"2025-04-10T05:24:00.235238Z","shell.execute_reply.started":"2025-04-10T05:24:00.050586Z","shell.execute_reply":"2025-04-10T05:24:00.234354Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If you received an error response along the lines of `No user secrets exist for kernel id ...`, then you need to add your API key via `Add-ons`, `Secrets` **and** enable it.\n\n![Screenshot of the checkbox to enable GOOGLE_API_KEY secret](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_3.png)","metadata":{"id":"25b2127c2052"},"attachments":{"53e1d527-de81-497e-bfac-58df458e750b.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"### Explore available models\n\nYou will be using the [`TunedModel.create`](https://ai.google.dev/api/tuning#method:-tunedmodels.create) API method to start the fine-tuning job and create your custom model. Find a model that supports it through the [`models.list`](https://ai.google.dev/api/models#method:-models.list) endpoint. You can also find more information about tuning models in [the model tuning docs](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?lang=python).","metadata":{"id":"CqVA5QFO6n4z"}},{"cell_type":"code","source":"for model in client.models.list():\n        print(model.name)","metadata":{"id":"coEacWAB6o0G","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.236388Z","iopub.execute_input":"2025-04-10T05:24:00.236669Z","iopub.status.idle":"2025-04-10T05:24:00.308888Z","shell.execute_reply.started":"2025-04-10T05:24:00.236641Z","shell.execute_reply":"2025-04-10T05:24:00.308060Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Use the dataset\n\nIn this activity, you will use the same newsgroups dataset that [you used to train a classifier in Keras](https://www.kaggle.com/code/markishere/day-2-classifying-embeddings-with-keras/). In this example you will use a fine-tuned Gemini model to achieve the same goal.\n\nThe [20 Newsgroups Text Dataset](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) contains 18,000 newsgroups posts on 20 topics divided into training and test sets.","metadata":{"id":"peFm0w_0c1CO"}},{"cell_type":"code","source":"# Load your transaction data\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load your data\nfile_path = \"/kaggle/input/training/categorized_transaction.csv\"\ndf = pd.read_csv(file_path)\n\n# Split into train and test sets (80/20 split)\ndf_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n\n# Display the subcategories (labels) in your dataset\nsubcategories = df['subcategory'].unique()\nprint(f\"Number of subcategories: {len(subcategories)}\")\nprint(\"Sample subcategories:\", subcategories[:10])  # Show first 10 subcategories\n\n# Quick look at note examples\nprint(\"\\nSample notes:\")\nfor i, note in enumerate(df['note'].head(3)):\n    print(f\"{i+1}. {note} → {df['subcategory'].iloc[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.309841Z","iopub.execute_input":"2025-04-10T05:24:00.310093Z","iopub.status.idle":"2025-04-10T05:24:00.338201Z","shell.execute_reply.started":"2025-04-10T05:24:00.310067Z","shell.execute_reply":"2025-04-10T05:24:00.336606Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prepare the dataset\n\nYou'll use the same pre-processing code you used for the custom model on day 2. This pre-processing removes personal information, which can be used to \"shortcut\" to known users of a forum, and formats the text to appear a bit more like regular text and less like a newsgroup post (e.g. by removing the mail headers). This normalisation allows the model to generalise to regular text and not over-depend on specific fields. If your input data is always going to be newsgroup posts, it may be helpful to leave this structure in place if they provide genuine signals.","metadata":{"id":"03lDs1O4ZQ0-"}},{"cell_type":"markdown","source":"Now sample the data. You will keep 50 rows for each category for training. Note that this is even fewer than the Keras example, as this technique (parameter-efficient fine-tuning, or PEFT) updates a relatively small number of parameters and does not require training a new model or updating the large model.","metadata":{"id":"XSKcj5WtadaR"}},{"cell_type":"code","source":"def sample_data(df, num_samples):\n    \"\"\"\n    Sample rows from each subcategory, selecting num_samples from each.\n    If a subcategory has fewer than num_samples entries, takes all available rows.\n    \n    Args:\n        df: DataFrame containing transaction data\n        num_samples: Number of samples to take per subcategory\n        \n    Returns:\n        DataFrame with balanced samples across subcategories\n    \"\"\"\n    # Group by subcategory and sample\n    sampled_df = (\n        df.groupby(\"subcategory\")[df.columns]\n        .apply(lambda x: x.sample(min(len(x), num_samples)))\n        .reset_index(drop=True)\n    )\n    \n    # Convert subcategory to category type for efficiency\n    sampled_df[\"subcategory\"] = sampled_df[\"subcategory\"].astype(\"category\")\n    \n    return sampled_df\n\n# Sample training and test data\nTRAIN_NUM_SAMPLES = 50  # 50 samples per subcategory for training\nTEST_NUM_SAMPLES = 10   # 10 samples per subcategory for testing\n\n# Create balanced datasets\ndf_train_sampled = sample_data(df_train, TRAIN_NUM_SAMPLES)\ndf_test_sampled = sample_data(df_test, TEST_NUM_SAMPLES)\n\n# Print statistics about the sampled data\nprint(f\"Original training data: {len(df_train)} rows\")\nprint(f\"Sampled training data: {len(df_train_sampled)} rows\")\nprint(f\"Number of subcategories: {df_train_sampled['subcategory'].nunique()}\")\n\n# Show distribution of a few subcategories\nprint(\"\\nSample of subcategory counts in training data:\")\nprint(df_train_sampled['subcategory'].value_counts().head(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.339476Z","iopub.execute_input":"2025-04-10T05:24:00.339807Z","iopub.status.idle":"2025-04-10T05:24:00.378071Z","shell.execute_reply.started":"2025-04-10T05:24:00.339771Z","shell.execute_reply":"2025-04-10T05:24:00.376632Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate baseline performance\n\nBefore you start tuning a model, it's good practice to perform an evaluation on the available models to ensure you can measure how much the tuning helps.\n\nFirst identify a single sample row to use for visual inspection.","metadata":{}},{"cell_type":"code","source":"import sqlite3\n\n# Connect to your database\ndb_conn = sqlite3.connect('/kaggle/working/transaction_categories.db')\ncursor = db_conn.cursor()\n\n# Create the tables\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS categories (\n    category_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    name VARCHAR(100) NOT NULL UNIQUE,\n    description TEXT,\n    display_order INT DEFAULT 100,\n    is_active BOOLEAN DEFAULT 1,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS subcategories (\n    subcategory_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    category_id INTEGER NOT NULL,\n    name VARCHAR(100) NOT NULL,\n    description TEXT,\n    display_order INT DEFAULT 100,\n    is_active BOOLEAN DEFAULT 1,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (category_id) REFERENCES categories(category_id)\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS keyword_rules (\n    rule_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    category_id INTEGER NOT NULL,\n    subcategory_id INTEGER,\n    keyword VARCHAR(255) NOT NULL,\n    match_type VARCHAR(20) DEFAULT 'contains',\n    priority INT DEFAULT 100,\n    is_active BOOLEAN DEFAULT 1,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    created_by VARCHAR(100),\n    FOREIGN KEY (category_id) REFERENCES categories(category_id),\n    FOREIGN KEY (subcategory_id) REFERENCES subcategories(subcategory_id)\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS transaction_categories (\n    transaction_id VARCHAR(100) PRIMARY KEY,\n    category_id INTEGER,\n    subcategory_id INTEGER,\n    confidence_score DECIMAL(5,4),\n    categorization_method VARCHAR(50),\n    is_manually_reviewed BOOLEAN DEFAULT 0,\n    categorized_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (category_id) REFERENCES categories(category_id),\n    FOREIGN KEY (subcategory_id) REFERENCES subcategories(subcategory_id)\n)\n''')\n\n# Insert main categories\ncategories = [\n    ('Food & Beverages', 'Expenses related to food and drinks', 10),\n    ('Shopping', 'Retail purchases and shopping expenses', 20),\n    ('Housing', 'Home-related expenses including rent and utilities', 30),\n    ('Transportation', 'Public and private transportation costs', 40),\n    ('Vehicle', 'Car and vehicle related expenses', 50),\n    ('Life & Entertainment', 'Leisure activities and entertainment', 60),\n    ('Communication, PC', 'Internet, phone and computer expenses', 70),\n    ('Financial expenses', 'Banking fees, loans, and financial costs', 80),\n    ('Investments', 'Investment-related transactions', 90),\n    ('Income', 'All sources of incoming money', 100),\n    ('Transfer', 'Money transfers between accounts', 110)\n]\n\ncursor.executemany('INSERT OR IGNORE INTO categories (name, description, display_order) VALUES (?, ?, ?)', categories)\n\n# Insert subcategories for Food & Beverages\nfood_subcategories = [\n    (1, 'Bar, cafe, drink, snacks', 10),\n    (1, 'Groceries', 20),\n    (1, 'Restaurant, fast-food', 30)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', food_subcategories)\n\n# Insert subcategories for Shopping\nshopping_subcategories = [\n    (2, 'Clothes & Footwear', 10),\n    (2, 'Drug-store, chemist', 20),\n    (2, 'Electronics, accessories', 30),\n    (2, 'Gifts, joy', 40),\n    (2, 'Health and beauty', 50),\n    (2, 'Home, garden', 60),\n    (2, 'Jewels, accessories', 70),\n    (2, 'Kids', 80),\n    (2, 'Leisure time', 90),\n    (2, 'Pets, animals', 100),\n    (2, 'Stationery, tools', 110)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', shopping_subcategories)\n\nhousing_subcategories=[\n    (3, 'Energy, utilities', 10),\n    (3, 'Maintenance, repairs', 20),\n    (3, 'Mortgage', 30),\n    (3, 'Property insurance', 40),\n    (3, 'Rent', 50),\n    (3, 'Services', 60)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', housing_subcategories)\n\n\ntransportation_subcategories=[\n    (4, 'Business trips', 10),\n    (4, 'Long distance', 20),\n    (4, 'Public transport', 30),\n    (4, 'Taxi', 40)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', transportation_subcategories)\n\nvehicle_subcategories=[\n    (5, 'Fuel', 10),\n    (5, 'Leasing', 20),\n    (5, 'Parking', 30),\n    (5, 'Rentals', 40),\n    (5, 'Vehicle insurance', 50),\n    (5, 'Vehicle maintenance', 60)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', vehicle_subcategories)\n\nlife_subcategories=[\n    (6, 'Active sport, fitness', 10),\n    (6, 'Alcohol, tobacco', 20),\n    (6, 'Books, audio, subscriptions', 30),\n    (6, 'Charity, gifts', 40),\n    (6, 'Culture, sport events', 50),\n    (6, 'Education, development', 60),\n    (6, 'Health care, doctor', 70),\n    (6, 'Hobbies', 80),\n    (6, 'Holiday, trips, hotels', 90),\n    (6, 'Life events', 100),\n    (6, 'Lottery, gambling', 110),\n    (6, 'TV, Streaming', 120),\n    (6, 'Wellness, beauty', 130)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', life_subcategories)\n\ncommunication_subcategories=[\n    (7, 'Internet', 10),\n    (7, 'Postal services', 20),\n    (7, 'Software, apps, games', 30),\n    (7, 'Telephony, mobile phone', 40)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', communication_subcategories)\n\nfinancial_subcategories=[\n    (8, 'Advisory', 10),\n    (8, 'Charges, Fees', 20),\n    (8, 'Child Support', 30),\n    (8, 'Fines', 40),\n    (8, 'Insurances', 50),\n    (8, 'Loans, interests', 60),\n    (8, 'Taxes', 70)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', financial_subcategories)\n\ninvestments_subcategories=[\n    (9, 'Collections', 10),\n    (9, 'Financial investments', 20),\n    (9, 'Realty', 30),\n    (9, 'Savings', 40),\n    (9, 'Vehicles, chattels', 50)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', investments_subcategories)\n\nincome_subcategories=[\n    (10, 'Checks, coupons', 10),\n    (10, 'Child Support', 20),\n    (10, 'Dues & grants', 30),\n    (10, 'Gifts', 40),\n    (10, 'Interests, dividends', 50),\n    (10, 'Lending, renting', 60),\n    (10, 'Lottery, gambling', 70),\n    (10, 'Refunds (tax, purchase)', 80),\n    (10, 'Rental income', 90),\n    (10, 'Sale', 100),\n    (10, 'Wage, invoices', 110)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', income_subcategories)\n\ntransfer_subcatgories=[\n    (11, 'Transfer', 10),   \n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', transfer_subcatgories)\n\n# Commit the changes\ndb_conn.commit()\nprint(\"Database schema created successfully!\")\n\n# Close the connection when done\ndb_conn.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.379806Z","iopub.execute_input":"2025-04-10T05:24:00.380270Z","iopub.status.idle":"2025-04-10T05:24:00.412849Z","shell.execute_reply.started":"2025-04-10T05:24:00.380223Z","shell.execute_reply":"2025-04-10T05:24:00.411804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":" import sqlite3\n\ndb_file = \"transaction_categories.db\"\ndb_conn = sqlite3.connect(db_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.416956Z","iopub.execute_input":"2025-04-10T05:24:00.417336Z","iopub.status.idle":"2025-04-10T05:24:00.422342Z","shell.execute_reply.started":"2025-04-10T05:24:00.417302Z","shell.execute_reply":"2025-04-10T05:24:00.420981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.api_core import retry\n\n# Define a system instruction for classification with the subcategories list\nsystem_instruct = \"\"\"\nYou are a financial transaction categorization service. You will be provided with a transaction \ndescription (note) and must classify it into exactly one of the following subcategories:\n\n{}\n\nYour response must be ONLY the exact subcategory name from this list, with no additional text.\nDo not create new categories or modify existing ones.\nIf uncertain, choose the most likely subcategory from the list above.\n\"\"\"\n\n# Get the list of subcategories and format them for the prompt\nall_subcategories = sorted(df['subcategory'].unique())\nsubcategories_text = \"\\n\".join([f\"- {subcat}\" for subcat in all_subcategories])\n\n# Insert the subcategories into the system instruction\nsystem_instruct = system_instruct.format(subcategories_text)\n\n# Define a helper to retry when per-minute quota is reached\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n@retry.Retry(predicate=is_retriable)\ndef predict_label(transaction_note: str) -> str:\n    \"\"\"Classify the provided transaction note into a subcategory from the predefined list.\"\"\"\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        config=types.GenerateContentConfig(\n            system_instruction=system_instruct),\n        contents=transaction_note)\n    rc = response.candidates[0]\n    \n    # Any errors, filters, recitation, etc we can mark as a general error\n    if rc.finish_reason.name != \"STOP\":\n        return \"(error)\"\n    else:\n        # Clean up the response\n        prediction = response.text.strip()\n        \n        # Verify the prediction is from our list of subcategories\n        if prediction in all_subcategories:\n            return prediction\n        else:\n            # Find the closest matching subcategory if possible\n            for subcat in all_subcategories:\n                if subcat.lower() in prediction.lower():\n                    return subcat\n            return \"(invalid category)\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.423374Z","iopub.execute_input":"2025-04-10T05:24:00.423691Z","iopub.status.idle":"2025-04-10T05:24:00.436640Z","shell.execute_reply.started":"2025-04-10T05:24:00.423662Z","shell.execute_reply":"2025-04-10T05:24:00.435320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tqdm\nfrom tqdm.rich import tqdm as tqdmr\nimport warnings\n\n# Enable tqdm features on Pandas\ntqdmr.pandas()\n\n# Suppress the experimental warning\nwarnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n\n# Further sample the test data to be mindful of the free-tier quota\n# Sample a small subset of test data (adjust number as needed)\nTEST_SAMPLE_SIZE = 20\ndf_baseline_eval = df_test_sampled.sample(min(TEST_SAMPLE_SIZE, len(df_test_sampled)))\n\nprint(f\"Evaluating {len(df_baseline_eval)} transactions...\")\n\n# Make predictions using the sampled data with progress bar\ndf_baseline_eval['prediction'] = df_baseline_eval['note'].progress_apply(predict_label)\n\n# Calculate the accuracy\naccuracy = (df_baseline_eval['subcategory'] == df_baseline_eval['prediction']).mean()\nprint(f\"Baseline accuracy: {accuracy:.2%}\")\n\n# Display some examples of predictions\nprint(\"\\nSample predictions:\")\nsample_results = df_baseline_eval[['note', 'subcategory', 'prediction']].sample(min(5, len(df_baseline_eval)))\nfor idx, row in sample_results.iterrows():\n    print(f\"Transaction: {row['note'][:50]}...\")\n    print(f\"True subcategory: {row['subcategory']}\")\n    print(f\"Predicted: {row['prediction']}\")\n    print(f\"Correct: {row['subcategory'] == row['prediction']}\\n\")\n\n# Create a confusion matrix to see where the model is making mistakes\nprint(\"Most common error patterns:\")\nerror_patterns = df_baseline_eval[df_baseline_eval['subcategory'] != df_baseline_eval['prediction']]\nif len(error_patterns) > 0:\n    error_counts = error_patterns.groupby(['subcategory', 'prediction']).size().reset_index(name='count')\n    error_counts = error_counts.sort_values('count', ascending=False)\n    print(error_counts.head(5))\nelse:\n    print(\"No errors found in the evaluation set!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:00.437820Z","iopub.execute_input":"2025-04-10T05:24:00.438134Z","iopub.status.idle":"2025-04-10T05:24:07.933068Z","shell.execute_reply.started":"2025-04-10T05:24:00.438089Z","shell.execute_reply":"2025-04-10T05:24:07.932305Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections.abc import Iterable\nimport datetime\nimport time\nimport os\n\n# 1. Prepare your transaction data for fine-tuning\nprint(\"Preparing transaction data for fine-tuning...\")\n\n# Convert the DataFrame into the format expected by the API\ntraining_examples = []\nfor _, row in df_train_sampled.iterrows():\n    training_examples.append({\n        \"textInput\": str(row['note']),\n        \"output\": str(row['subcategory'])\n    })\n\nprint(f\"Created {len(training_examples)} training examples\")\nprint(f\"Sample example - Input: '{training_examples[0]['textInput'][:50]}...'\")\nprint(f\"Sample example - Output: '{training_examples[0]['output']}'\")\n\n# 2. Prepare the dataset in the required format\ntraining_data = {\"examples\": training_examples}\n\n# Check for existing model to reuse\nmodel_id = None\n    \n    try:\n        # Try to read previous model ID from file\n        try:\n            with open(\"tuned_model_id.txt\", \"r\") as f:\n                saved_model_id = f.read().strip()\n                if saved_model_id:\n                    print(f\"Found previously saved model ID: {saved_model_id}\")\n                    model_id = saved_model_id\n        except FileNotFoundError:\n            print(\"No previously saved model ID found.\")\n        \n        # If no saved ID, check for existing models\n        if not model_id:\n            queued_model = None\n            print(\"Checking for existing tuned models...\")\n            \n            # List models in reverse order (newest first)\n            for m in reversed(client.tunings.list()):\n                # Look for models with your specific format tunedModels/personal-transaction-classifier-*\n                if m.name.startswith('tunedModels/personal-transaction-classifier-'):\n                    # If there is a completed model, use it\n                    if m.state.name == 'JOB_STATE_SUCCEEDED':\n                        model_id = m.name\n                        print(f'Found existing completed model to reuse: {model_id}')\n                        break\n                    elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n                        # If there's a model still running, remember it\n                        queued_model = m.name\n                        print(f'Found model still in progress: {queued_model}')\n            \n            # Use queued model if found and no completed model\n            if not model_id and queued_model:\n                model_id = queued_model\n                print(f'Using in-progress model: {model_id}')\n        \n        # Create new model if needed\n        if not model_id:\n            print(\"Starting new fine-tuning job...\")\n            tuning_op = client.tunings.tune(\n                base_model=\"models/gemini-1.5-flash-001-tuning\",\n                training_dataset=training_data,\n                config=types.CreateTuningJobConfig(\n                    tuned_model_display_name=\"personal-transaction-classifier\",  # Lowercase to match your existing model\n                    batch_size=16,\n                    epoch_count=3,\n                ),\n            )\n            \n            model_id = tuning_op.name\n            print(f\"Fine-tuning initiated. Model ID: {model_id}\")\n            print(f\"Current status: {tuning_op.state}\")\n            \n            # Poll for status updates (optional)\n            print(\"Initial training status:\")\n            print(f\"  - State: {tuning_op.state}\")\n            print(f\"  - Create time: {tuning_op.create_time}\")\n            if hasattr(tuning_op, 'progress') and tuning_op.progress:\n                print(f\"  - Progress: {tuning_op.progress}%\")\n        \n        # Save the model ID for later use\n        with open(\"tuned_model_id.txt\", \"w\") as f:\n            f.write(model_id)\n        \n        print(f\"\\nUsing model: {model_id}\")\n        print(\"This ID has been saved and will be used for predictions\")\n        \n    except Exception as e:\n        print(f\"Error in fine-tuning process: {e}\")\nelse:\n    print(\"No valid training examples created. Please fix the issues above.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:45:25.172825Z","iopub.execute_input":"2025-04-10T05:45:25.173226Z","iopub.status.idle":"2025-04-10T05:45:25.184573Z","shell.execute_reply.started":"2025-04-10T05:45:25.173191Z","shell.execute_reply":"2025-04-10T05:45:25.182840Z"}},"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[289], line 27\u001b[0;36m\u001b[0m\n\u001b[0;31m    try:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"],"ename":"IndentationError","evalue":"unexpected indent (2092435916.py, line 27)","output_type":"error"}],"execution_count":289},{"cell_type":"code","source":"# 3. Set up the fine-tuning job - find existing or create new\nmodel_id = None\nTUNED_MODEL_PREFIX = 'tunedModels/transaction-category-classifier'\n\ntry:\n    # Try to read previous model ID from file\n    if os.path.exists(\"tuned_model_id.txt\"):\n        with open(\"tuned_model_id.txt\", \"r\") as f:\n            saved_model_id = f.read().strip()\n            if saved_model_id:\n                print(f\"Found previously saved model ID: {saved_model_id}\")\n                model_id = saved_model_id\n    \n    # If no saved ID, check for existing models\n    if not model_id:\n        queued_model = None\n        print(\"Checking for existing tuned models...\")\n        \n        # List models in reverse order (newest first)\n        for m in reversed(client.tunings.list()):\n            # Look for transaction classification models\n            if m.name.startswith(TUNED_MODEL_PREFIX):\n                # If there is a completed model, use it\n                if m.state.name == 'JOB_STATE_SUCCEEDED':\n                    model_id = m.name\n                    print(f'Found existing completed model to reuse: {model_id}')\n                    break\n                elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n                    # If there's a model still running, remember it\n                    queued_model = m.name\n                    print(f'Found model still in progress: {queued_model}')\n        \n        # Use queued model if found and no completed model\n        if not model_id and queued_model:\n            model_id = queued_model\n            print(f'Using in-progress model: {model_id}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:42:37.999773Z","iopub.execute_input":"2025-04-10T05:42:38.000169Z","iopub.status.idle":"2025-04-10T05:42:38.010009Z","shell.execute_reply.started":"2025-04-10T05:42:38.000118Z","shell.execute_reply":"2025-04-10T05:42:38.008409Z"}},"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[287], line 36\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'Using in-progress model: {model_id}')\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"],"ename":"SyntaxError","evalue":"incomplete input (2639960162.py, line 36)","output_type":"error"}],"execution_count":287},{"cell_type":"code","source":"# Create new model if needed\n    if not model_id:\n        print(\"Starting new fine-tuning job...\")\n        tuning_op = client.tunings.tune(\n            base_model=\"models/gemini-1.5-flash-001-tuning\",\n            training_dataset=training_data,\n            config=types.CreateTuningJobConfig(\n                tuned_model_display_name=\"transaction-category-classifier\",\n                batch_size=16,\n                epoch_count=3,\n            ),\n        )\n        \n        model_id = tuning_op.name\n        print(f\"Fine-tuning initiated. Model ID: {model_id}\")\n        print(f\"Current status: {tuning_op.state}\")\n    \n    # Save the model ID for later use\n    with open(\"tuned_model_id.txt\", \"w\") as f:\n        f.write(model_id)\n    \n    print(f\"\\nUsing model: {model_id}\")\n    \nexcept Exception as e:\n    print(f\"Error in fine-tuning process: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. Monitor the fine-tuning progress\nMAX_WAIT = datetime.timedelta(minutes=10)\nprint(f\"Monitoring fine-tuning progress for up to {MAX_WAIT.total_seconds()/60} minutes...\")\n\nstart_time = datetime.datetime.now(datetime.timezone.utc)\ntuned_model = client.tunings.get(name=model_id)\n\nwhile not tuned_model.has_ended:\n    print(f\"Current state: {tuned_model.state.name}\")\n    if hasattr(tuned_model, 'progress'):\n        print(f\"Progress: {tuned_model.progress}%\")\n    \n    time.sleep(60)  # Check every minute\n    tuned_model = client.tunings.get(name=model_id)\n    \n    # Don't wait too long\n    if datetime.datetime.now(datetime.timezone.utc) - start_time > MAX_WAIT:\n        print(\"Maximum wait time reached. Using the model in its current state.\")\n        break\n\nprint(f\"Done! The model state is: {tuned_model.state.name}\")\n\nif not tuned_model.has_succeeded and tuned_model.error:\n    print(\"Error:\", tuned_model.error)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Loading training data...\")\ntraining_file_path = \"/kaggle/input/training/categorized_transaction.csv\"\n\ntry:\n    df_training = pd.read_csv(training_file_path)\n    print(f\"Successfully loaded {len(df_training)} training examples\")\n    \n    # Print sample to verify columns\n    print(\"\\nSample of training data:\")\n    print(df_training.head(2))\n    print(\"\\nColumns in training data:\", df_training.columns.tolist())\n    \nexcept FileNotFoundError:\n    print(f\"ERROR: Could not find file at {training_file_path}\")\n    print(\"Please ensure your CSV is uploaded to the correct location\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:34:08.597504Z","iopub.execute_input":"2025-04-10T05:34:08.597912Z","iopub.status.idle":"2025-04-10T05:34:08.630764Z","shell.execute_reply.started":"2025-04-10T05:34:08.597878Z","shell.execute_reply":"2025-04-10T05:34:08.629616Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nSuccessfully loaded 12449 training examples\n\nSample of training data:\n             subcategory                                               note\n0  Active sport, fitness  AMAZON AU      SYDNEY SOUTH CREDIT CARD PURCHA...\n1  Active sport, fitness  02 DEC 20 - $98.00 LULULEMON ATHLETICA AUSTRAl...\n\nColumns in training data: ['subcategory', 'note']\n","output_type":"stream"}],"execution_count":285},{"cell_type":"code","source":"print(\"\\nCreating training examples...\")\ntraining_examples = []\n\n# Check if the required columns exist\nif 'note' not in df_training.columns or 'subcategory' not in df_training.columns:\n    print(\"ERROR: Training data must have 'note' and 'subcategory' columns\")\n    print(f\"Available columns: {df_training.columns.tolist()}\")\nelse:\n    # Filter out rows with NaN values in the 'note' column\n    df_valid = df_training.dropna(subset=['note'])\n    \n    print(f\"Original data: {len(df_training)} rows\")\n    print(f\"After removing NaN values: {len(df_valid)} rows\")\n    print(f\"Removed {len(df_training) - len(df_valid)} rows with missing descriptions\")\n    \n    for _, row in df_valid.iterrows():\n        # Create training example with correct fields\n        training_examples.append({\n            \"textInput\": str(row['note']),  # Ensure it's a string\n            \"output\": str(row['subcategory'])  # Ensure it's a string\n        })\n    \n    print(f\"Created {len(training_examples)} training examples\")\n    \n    # Optionally show a few examples\n    print(\"\\nSample training examples:\")\n    for example in training_examples[:3]:\n        print(f\"Input: '{example['textInput'][:50]}...'\")\n        print(f\"Output: '{example['output']}'\")\n        print(\"---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections.abc import Iterable\n\nif len(training_examples) > 0:\n    print(\"\\nPreparing for fine-tuning process...\")\n    \n    # Prepare training data in the required format\n    training_data = {\"examples\": training_examples}\n    \n    # Check for existing model to reuse\n    model_id = None\n    \n    try:\n        # Try to read previous model ID from file\n        try:\n            with open(\"tuned_model_id.txt\", \"r\") as f:\n                saved_model_id = f.read().strip()\n                if saved_model_id:\n                    print(f\"Found previously saved model ID: {saved_model_id}\")\n                    model_id = saved_model_id\n        except FileNotFoundError:\n            print(\"No previously saved model ID found.\")\n        \n        # If no saved ID, check for existing models\n        if not model_id:\n            queued_model = None\n            print(\"Checking for existing tuned models...\")\n            \n            # List models in reverse order (newest first)\n            for m in reversed(client.tunings.list()):\n                # Look for models with your specific format tunedModels/personal-transaction-classifier-*\n                if m.name.startswith('tunedModels/personal-transaction-classifier-'):\n                    # If there is a completed model, use it\n                    if m.state.name == 'JOB_STATE_SUCCEEDED':\n                        model_id = m.name\n                        print(f'Found existing completed model to reuse: {model_id}')\n                        break\n                    elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n                        # If there's a model still running, remember it\n                        queued_model = m.name\n                        print(f'Found model still in progress: {queued_model}')\n            \n            # Use queued model if found and no completed model\n            if not model_id and queued_model:\n                model_id = queued_model\n                print(f'Using in-progress model: {model_id}')\n        \n        # Create new model if needed\n        if not model_id:\n            print(\"Starting new fine-tuning job...\")\n            tuning_op = client.tunings.tune(\n                base_model=\"models/gemini-1.5-flash-001-tuning\",\n                training_dataset=training_data,\n                config=types.CreateTuningJobConfig(\n                    tuned_model_display_name=\"personal-transaction-classifier\",  # Lowercase to match your existing model\n                    batch_size=16,\n                    epoch_count=3,\n                ),\n            )\n            \n            model_id = tuning_op.name\n            print(f\"Fine-tuning initiated. Model ID: {model_id}\")\n            print(f\"Current status: {tuning_op.state}\")\n            \n            # Poll for status updates (optional)\n            print(\"Initial training status:\")\n            print(f\"  - State: {tuning_op.state}\")\n            print(f\"  - Create time: {tuning_op.create_time}\")\n            if hasattr(tuning_op, 'progress') and tuning_op.progress:\n                print(f\"  - Progress: {tuning_op.progress}%\")\n        \n        # Save the model ID for later use\n        with open(\"tuned_model_id.txt\", \"w\") as f:\n            f.write(model_id)\n        \n        print(f\"\\nUsing model: {model_id}\")\n        print(\"This ID has been saved and will be used for predictions\")\n        \n    except Exception as e:\n        print(f\"Error in fine-tuning process: {e}\")\nelse:\n    print(\"No valid training examples created. Please fix the issues above.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:32:17.297768Z","iopub.execute_input":"2025-04-10T05:32:17.298188Z","iopub.status.idle":"2025-04-10T05:32:17.338019Z","shell.execute_reply.started":"2025-04-10T05:32:17.298150Z","shell.execute_reply":"2025-04-10T05:32:17.336455Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[284], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Iterable\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtraining_examples\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPreparing for fine-tuning process...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Prepare training data in the required format\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'training_examples' is not defined"],"ename":"NameError","evalue":"name 'training_examples' is not defined","output_type":"error"}],"execution_count":284},{"cell_type":"code","source":"# Get valid subcategories from the database\ndef get_valid_subcategories():\n    \"\"\"Get all valid subcategory names from the database.\"\"\"\n    cursor = db_conn.cursor()\n    cursor.execute(\"SELECT DISTINCT name FROM subcategories\")\n    subcategories = cursor.fetchall()\n    # Return a deduplicated list of subcategory names\n    return sorted(list(set([subcat[0] for subcat in subcategories])))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:07.934217Z","iopub.execute_input":"2025-04-10T05:24:07.934540Z","iopub.status.idle":"2025-04-10T05:24:07.940212Z","shell.execute_reply.started":"2025-04-10T05:24:07.934506Z","shell.execute_reply":"2025-04-10T05:24:07.939149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"valid_subcategories = get_valid_subcategories()\n\ndef predict_label(transaction_note):\n    \"\"\"\n    Predict the subcategory for a transaction using direct approach with predefined categories.\n    \n    Args:\n        transaction_note: The transaction description to categorize\n        \n    Returns:\n        The predicted subcategory name\n    \"\"\"\n    # Build the prompt with the valid subcategories\n    subcategory_list = \"\\n\".join(valid_subcategories)\n    \n    direct_instruction = f\"\"\"\nYou are a financial transaction categorizer. Your task is to categorize transaction descriptions into exactly ONE subcategory from this list:\n\n{subcategory_list}\n\nReturn ONLY the subcategory name as a string, nothing else. Do not make up new subcategories or modify existing ones. \n\"\"\"\n\n    # Call the model directly\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        config=types.GenerateContentConfig(\n            system_instruction=direct_instruction,\n            temperature=0.0,\n            top_p=1.0,\n            top_k=1,\n            max_output_tokens=10,\n        ),\n        contents=f\"Categorize this transaction: {transaction_note}\"\n    )\n    \n    # Extract the prediction from the response\n    if response.candidates and response.candidates[0].content:\n        prediction = response.candidates[0].content.parts[0].text.strip()\n        return prediction\n    else:\n        return \"Error: No response generated\"\n    return prediction","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:07.941350Z","iopub.execute_input":"2025-04-10T05:24:07.941590Z","iopub.status.idle":"2025-04-10T05:24:07.960484Z","shell.execute_reply.started":"2025-04-10T05:24:07.941566Z","shell.execute_reply":"2025-04-10T05:24:07.959259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def test_multiple_transactions(df_test_sampled, num_samples=5):\n    \"\"\"\n    Test the model on multiple transactions and calculate accuracy.\n    \n    Args:\n        df_test_sampled: DataFrame containing test data\n        num_samples: Number of transactions to test\n    \n    Returns:\n        Dictionary with test results and accuracy\n    \"\"\"\n    # Ensure we don't try to test more samples than we have\n    num_samples = min(num_samples, len(df_test_sampled))\n    \n    results = []\n    correct_count = 0\n    \n    print(f\"Testing {num_samples} transactions:\")\n    print(\"=\" * 50)\n    \n    # Test each sample\n    for i in range(num_samples):\n        sample_row = df_test_sampled.iloc[i]\n        sample_note = sample_row['note']\n        sample_subcategory = sample_row['subcategory']\n        \n        # Make prediction\n        prediction = predict_label(sample_note)\n        \n        # Check if prediction is correct\n        is_correct = prediction == sample_subcategory\n        if is_correct:\n            correct_count += 1\n        \n        # Store result\n        results.append({\n            \"note\": sample_note,\n            \"true_subcategory\": sample_subcategory,\n            \"predicted_subcategory\": prediction,\n            \"correct\": is_correct\n        })\n        \n        # Print result\n        print(f\"Transaction {i+1}:\")\n        print(f\"Note: {sample_note}\")\n        print(f\"True subcategory: {sample_subcategory}\")\n        print(f\"Predicted subcategory: {prediction}\")\n        print(f\"Correct: {is_correct}\")\n        print(\"-\" * 50)\n    \n    # Calculate accuracy\n    accuracy = correct_count / num_samples\n    print(f\"Overall accuracy: {accuracy:.2%} ({correct_count}/{num_samples})\")\n    \n    return {\n        \"results\": results,\n        \"accuracy\": accuracy\n    }\n\n# Run the test with 5 samples\ntest_results = test_multiple_transactions(df_test_sampled, num_samples=5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:07.961764Z","iopub.execute_input":"2025-04-10T05:24:07.962041Z","iopub.status.idle":"2025-04-10T05:24:10.012884Z","shell.execute_reply.started":"2025-04-10T05:24:07.962017Z","shell.execute_reply":"2025-04-10T05:24:10.011500Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from google.api_core import retry\n\n# You can use a system instruction to do more direct prompting, and get a\n# more succinct answer.\n\nsystem_instruct = \"\"\"\nYou are a classification service. You will be passed note that represents\ntranscation details and you must respond with the subcategory from which the transaction\nbest fit.\n\"\"\"\n\n# Define a helper to retry when per-minute quota is reached.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n# If you want to evaluate your own technique, replace this body of this function\n# with your model, prompt and other code and return the predicted answer.\n@retry.Retry(predicate=is_retriable)\ndef predict_label(post: str) -> str:\n    response = client.models.generate_content(\n        model=\"gemini-1.5-flash-001\",\n        config=types.GenerateContentConfig(\n            system_instruction=system_instruct),\n        contents=post)\n\n    rc = response.candidates[0]\n\n    # Any errors, filters, recitation, etc we can mark as a general error\n    if rc.finish_reason.name != \"STOP\":\n        return \"(error)\"\n    else:\n        # Clean up the response.\n        return response.text.strip()\n\n\nprediction = predict_label(sample_row)\n\nprint(prediction)\nprint()\nprint(\"Correct!\" if prediction == sample_label else \"Incorrect.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.014400Z","iopub.execute_input":"2025-04-10T05:24:10.014719Z","iopub.status.idle":"2025-04-10T05:24:10.134338Z","shell.execute_reply.started":"2025-04-10T05:24:10.014689Z","shell.execute_reply":"2025-04-10T05:24:10.132914Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can use the prompt engineering techniques you have learned this week to induce the model to perform the desired task. Try some of your own ideas and see what is effective, or check out the following cells for different approaches. Note that they have different levels of effectiveness!","metadata":{}},{"cell_type":"code","source":"# Ask the model directly in a zero-shot prompt.\n\nprompt = \"From what subcategory does the following message originate?\"\nbaseline_response = client.models.generate_content(\n    model=\"gemini-2.0-flash-001\",\n    contents=[prompt, sample_row])\nprint(baseline_response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.135088Z","iopub.status.idle":"2025-04-10T05:24:10.135422Z","shell.execute_reply.started":"2025-04-10T05:24:10.135285Z","shell.execute_reply":"2025-04-10T05:24:10.135301Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This technique still produces quite a verbose response. You could try and parse out the relevant text, or refine the prompt even further.","metadata":{}},{"cell_type":"code","source":"from google.api_core import retry\n\n# You can use a system instruction to do more direct prompting, and get a\n# more succinct answer.\n\nsystem_instruct = \"\"\"\nYou are a classification service. You will be passed input that represents\na newsgroup post and you must respond with the newsgroup from which the post\noriginates.\n\"\"\"\n\n# Define a helper to retry when per-minute quota is reached.\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n# If you want to evaluate your own technique, replace this body of this function\n# with your model, prompt and other code and return the predicted answer.\n@retry.Retry(predicate=is_retriable)\ndef predict_label(post: str) -> str:\n    response = client.models.generate_content(\n        model=\"gemini-1.5-flash-001\",\n        config=types.GenerateContentConfig(\n            system_instruction=system_instruct),\n        contents=post)\n\n    rc = response.candidates[0]\n\n    # Any errors, filters, recitation, etc we can mark as a general error\n    if rc.finish_reason.name != \"STOP\":\n        return \"(error)\"\n    else:\n        # Clean up the response.\n        return response.text.strip()\n\n\nprediction = predict_label(sample_row)\n\nprint(prediction)\nprint()\nprint(\"Correct!\" if prediction == sample_label else \"Incorrect.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.136487Z","iopub.status.idle":"2025-04-10T05:24:10.136762Z","shell.execute_reply.started":"2025-04-10T05:24:10.136633Z","shell.execute_reply":"2025-04-10T05:24:10.136646Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now run a short evaluation using the function defined above. The test set is further sampled to ensure the experiment runs smoothly on the API's free tier. In practice you would evaluate over the whole set.","metadata":{}},{"cell_type":"code","source":"import tqdm\nfrom tqdm.rich import tqdm as tqdmr\nimport warnings\n\n# Enable tqdm features on Pandas.\ntqdmr.pandas()\n\n# But suppress the experimental warning\nwarnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n\n\n# Further sample the test data to be mindful of the free-tier quota.\ndf_baseline_eval = sample_data(df_test, 2, '.*')\n\n# Make predictions using the sampled data.\ndf_baseline_eval['Prediction'] = df_baseline_eval['Text'].progress_apply(predict_label)\n\n# And calculate the accuracy.\naccuracy = (df_baseline_eval[\"Class Name\"] == df_baseline_eval[\"Prediction\"]).sum() / len(df_baseline_eval)\nprint(f\"Accuracy: {accuracy:.2%}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.137974Z","iopub.status.idle":"2025-04-10T05:24:10.138295Z","shell.execute_reply.started":"2025-04-10T05:24:10.138141Z","shell.execute_reply":"2025-04-10T05:24:10.138161Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now take a look at the dataframe to compare the predictions with the labels.","metadata":{}},{"cell_type":"code","source":"df_baseline_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.139619Z","iopub.status.idle":"2025-04-10T05:24:10.139877Z","shell.execute_reply.started":"2025-04-10T05:24:10.139758Z","shell.execute_reply":"2025-04-10T05:24:10.139771Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Tune a custom model\n\nIn this example you'll use tuning to create a model that requires no prompting or system instructions and outputs succinct text from the classes you provide in the training data.\n\nThe data contains both input text (the processed posts) and output text (the category, or newsgroup), that you can use to start tuning a model.\n\nWhen calling `tune()`, you can specify model tuning hyperparameters too:\n - `epoch_count`: defines how many times to loop through the data,\n - `batch_size`: defines how many rows to process in a single step, and\n - `learning_rate`: defines the scaling factor for updating model weights at each step.\n\nYou can also choose to omit them and use the defaults. [Learn more](https://developers.google.com/machine-learning/crash-course/linear-regression/hyperparameters) about these parameters and how they work. For this example these parameters were selected by running some tuning jobs and selecting parameters that converged efficiently.\n\nThis example will start a new tuning job, but only if one does not already exist. This allows you to leave this codelab and come back later - re-running this step will find your last model.","metadata":{"id":"Ok7ugrLzcghX"}},{"cell_type":"code","source":"from collections.abc import Iterable\nimport random\n\n\n# Convert the data frame into a dataset suitable for tuning.\ninput_data = {'examples': \n    df_train[['Text', 'Class Name']]\n      .rename(columns={'Text': 'textInput', 'Class Name': 'output'})\n      .to_dict(orient='records')\n }\n\n# If you are re-running this lab, add your model_id here.\nmodel_id = None\n\n# Or try and find a recent tuning job.\nif not model_id:\n  queued_model = None\n  # Newest models first.\n  for m in reversed(client.tunings.list()):\n    # Only look at newsgroup classification models.\n    if m.name.startswith('tunedModels/newsgroup-classification-model'):\n      # If there is a completed model, use the first (newest) one.\n      if m.state.name == 'JOB_STATE_SUCCEEDED':\n        model_id = m.name\n        print('Found existing tuned model to reuse.')\n        break\n\n      elif m.state.name == 'JOB_STATE_RUNNING' and not queued_model:\n        # If there's a model still queued, remember the most recent one.\n        queued_model = m.name\n  else:\n    if queued_model:\n      model_id = queued_model\n      print('Found queued model, still waiting.')\n\n\n# Upload the training data and queue the tuning job.\nif not model_id:\n    tuning_op = client.tunings.tune(\n        base_model=\"models/gemini-1.5-flash-001-tuning\",\n        training_dataset=input_data,\n        config=types.CreateTuningJobConfig(\n            tuned_model_display_name=\"Newsgroup classification model\",\n            batch_size=16,\n            epoch_count=2,\n        ),\n    )\n\n    print(tuning_op.state)\n    model_id = tuning_op.name\n\nprint(model_id)","metadata":{"id":"pWOZlspfY8dV","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.140801Z","iopub.status.idle":"2025-04-10T05:24:10.141049Z","shell.execute_reply.started":"2025-04-10T05:24:10.140925Z","shell.execute_reply":"2025-04-10T05:24:10.140943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This has created a tuning job that will run in the background. To inspect the progress of the tuning job, run this cell to plot the current status and loss curve. Once the status reaches `ACTIVE`, tuning is complete and the model is ready to use.\n\nTuning jobs are queued, so it may look like no training steps have been taken initially but it will progress. Tuning can take anywhere from a few minutes to multiple hours, depending on factors like your dataset size and how busy the tuning infrastrature is. Why not treat yourself to a nice cup of tea while you wait, or come and say \"Hi!\" in the group [Discord](https://discord.com/invite/kaggle).\n\nIt is safe to stop this cell at any point. It will not stop the tuning job.\n\n**IMPORTANT**: Due to the high volume of users doing this course, tuning jobs may be queued for many hours. Take a note of your tuned model ID above (`tunedModels/...`) so you can come back to it tomorrow. In the meantime, check out the [Search grounding](https://www.kaggle.com/code/markishere/day-4-google-search-grounding/) codelab. If you want to try tuning a local LLM, check out [the fine-tuning guides for tuning a Gemma model](https://ai.google.dev/gemma/docs/tune).","metadata":{"id":"NQ3YZ2MBubCY"}},{"cell_type":"code","source":"import datetime\nimport time\n\n\nMAX_WAIT = datetime.timedelta(minutes=10)\n\nwhile not (tuned_model := client.tunings.get(name=model_id)).has_ended:\n\n    print(tuned_model.state)\n    time.sleep(60)\n\n    # Don't wait too long. Use a public model if this is going to take a while.\n    if datetime.datetime.now(datetime.timezone.utc) - tuned_model.create_time > MAX_WAIT:\n        print(\"Taking a shortcut, using a previously prepared model.\")\n        model_id = \"tunedModels/newsgroup-classification-model-ltenbi1b\"\n        tuned_model = client.tunings.get(name=model_id)\n        break\n\n\nprint(f\"Done! The model state is: {tuned_model.state.name}\")\n\nif not tuned_model.has_succeeded and tuned_model.error:\n    print(\"Error:\", tuned_model.error)","metadata":{"id":"c4ef5f13692d","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.142820Z","iopub.status.idle":"2025-04-10T05:24:10.143147Z","shell.execute_reply.started":"2025-04-10T05:24:10.142982Z","shell.execute_reply":"2025-04-10T05:24:10.142996Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Use the new model\n\nNow that you have a tuned model, try it out with custom data. You use the same API as a normal Gemini API interaction, but you specify your new model as the model name, which will start with `tunedModels/`.","metadata":{"id":"9-qiIdK4u80z"}},{"cell_type":"code","source":"new_text = \"\"\"\nFirst-timer looking to get out of here.\n\nHi, I'm writing about my interest in travelling to the outer limits!\n\nWhat kind of craft can I buy? What is easiest to access from this 3rd rock?\n\nLet me know how to do that please.\n\"\"\"\n\nresponse = client.models.generate_content(\n    model=model_id, contents=new_text)\n\nprint(response.text)","metadata":{"id":"hyO2-MXLvM6a","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.144577Z","iopub.status.idle":"2025-04-10T05:24:10.144864Z","shell.execute_reply.started":"2025-04-10T05:24:10.144730Z","shell.execute_reply":"2025-04-10T05:24:10.144745Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation\n\nYou can see that the model outputs labels that correspond to those in the training data, and without any system instructions or prompting, which is already a great improvement. Now see how well it performs on the test set.\n\nNote that there is no parallelism in this example; classifying the test sub-set will take a few minutes.","metadata":{"id":"xajLek9DySH_"}},{"cell_type":"code","source":"@retry.Retry(predicate=is_retriable)\ndef classify_text(text: str) -> str:\n    \"\"\"Classify the provided text into a known newsgroup.\"\"\"\n    response = client.models.generate_content(\n        model=model_id, contents=text)\n    rc = response.candidates[0]\n\n    # Any errors, filters, recitation, etc we can mark as a general error\n    if rc.finish_reason.name != \"STOP\":\n        return \"(error)\"\n    else:\n        return rc.content.parts[0].text\n\n\n# The sampling here is just to minimise your quota usage. If you can, you should\n# evaluate the whole test set with `df_model_eval = df_test.copy()`.\ndf_model_eval = sample_data(df_test, 4, '.*')\n\ndf_model_eval[\"Prediction\"] = df_model_eval[\"Text\"].progress_apply(classify_text)\n\naccuracy = (df_model_eval[\"Class Name\"] == df_model_eval[\"Prediction\"]).sum() / len(df_model_eval)\nprint(f\"Accuracy: {accuracy:.2%}\")","metadata":{"id":"6T2Y3ZApvbMw","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.146418Z","iopub.status.idle":"2025-04-10T05:24:10.146686Z","shell.execute_reply.started":"2025-04-10T05:24:10.146563Z","shell.execute_reply":"2025-04-10T05:24:10.146576Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Compare token usage\n\nAI Studio and the Gemini API provide model tuning at no cost, however normal limits and charges apply for *use* of a tuned model.\n\nThe size of the input prompt and other generation config like system instructions, as well as the number of generated output tokens, all contribute to the overall cost of a request.","metadata":{}},{"cell_type":"code","source":"# Calculate the *input* cost of the baseline model with system instructions.\nsysint_tokens = client.models.count_tokens(\n    model='gemini-1.5-flash-001', contents=[system_instruct, sample_row]\n).total_tokens\nprint(f'System instructed baseline model: {sysint_tokens} (input)')\n\n# Calculate the input cost of the tuned model.\ntuned_tokens = client.models.count_tokens(model=tuned_model.base_model, contents=sample_row).total_tokens\nprint(f'Tuned model: {tuned_tokens} (input)')\n\nsavings = (sysint_tokens - tuned_tokens) / tuned_tokens\nprint(f'Token savings: {savings:.2%}')  # Note that this is only n=1.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.147831Z","iopub.status.idle":"2025-04-10T05:24:10.148229Z","shell.execute_reply.started":"2025-04-10T05:24:10.148054Z","shell.execute_reply":"2025-04-10T05:24:10.148070Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The earlier verbose model also produced more output tokens than needed for this task.","metadata":{}},{"cell_type":"code","source":"baseline_token_output = baseline_response.usage_metadata.candidates_token_count\nprint('Baseline (verbose) output tokens:', baseline_token_output)\n\ntuned_model_output = client.models.generate_content(\n    model=model_id, contents=sample_row)\ntuned_tokens_output = tuned_model_output.usage_metadata.candidates_token_count\nprint('Tuned output tokens:', tuned_tokens_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T05:24:10.150721Z","iopub.status.idle":"2025-04-10T05:24:10.151198Z","shell.execute_reply.started":"2025-04-10T05:24:10.150975Z","shell.execute_reply":"2025-04-10T05:24:10.150997Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Next steps\n\nNow that you have tuned a classification model, try some other tasks, like tuning a model to respond with a specific tone or style using hand-written examples (or even generated examples!). Kaggle hosts [a number of datasets](https://www.kaggle.com/datasets) you can try out.\n\nLearn about [when supervised fine-tuning is most effective](https://cloud.google.com/blog/products/ai-machine-learning/supervised-fine-tuning-for-gemini-llm).\n\nAnd check out the [fine-tuning tutorial](https://ai.google.dev/gemini-api/docs/model-tuning/tutorial?hl=en&lang=python) for another example that shows a tuned model extending beyond the training data to new, unseen inputs.\n\n*- [Mark McD](https://linktr.ee/markmcd)*","metadata":{"id":"6c1204a5d0ab"}}]}