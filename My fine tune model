{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"name":"day-4-fine-tuning-a-custom-model.ipynb","toc_visible":true},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":11393223,"datasetId":7129309,"databundleVersionId":11827085}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## Load the subcategory and category table\nIn this step, I load the subcategory, category table.","metadata":{"execution":{"iopub.status.busy":"2025-04-13T22:04:48.593325Z","iopub.execute_input":"2025-04-13T22:04:48.594027Z","iopub.status.idle":"2025-04-13T22:04:48.603234Z","shell.execute_reply.started":"2025-04-13T22:04:48.593988Z","shell.execute_reply":"2025-04-13T22:04:48.601891Z"},"trusted":true},"outputs":[{"traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[102], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    In this step, I load the subcategory, category table.\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (1170953289.py, line 2)","output_type":"error"},{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"import sqlite3\n\n# Connect to your database\ndb_conn = sqlite3.connect('/kaggle/working/transaction_categories.db')\ncursor = db_conn.cursor()\n\n# Create the tables\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS categories (\n    category_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    name VARCHAR(100) NOT NULL UNIQUE,\n    description TEXT,\n    display_order INT DEFAULT 100,\n    is_active BOOLEAN DEFAULT 1,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n)\n''')\n\ncursor.execute('''\nCREATE TABLE IF NOT EXISTS subcategories (\n    subcategory_id INTEGER PRIMARY KEY AUTOINCREMENT,\n    category_id INTEGER NOT NULL,\n    name VARCHAR(100) NOT NULL,\n    description TEXT,\n    display_order INT DEFAULT 100,\n    is_active BOOLEAN DEFAULT 1,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    FOREIGN KEY (category_id) REFERENCES categories(category_id)\n)\n''')\n\n\n# Insert main categories\ncategories = [\n    ('Food & Beverages', 'Expenses related to food and drinks', 10),\n    ('Shopping', 'Retail purchases and shopping expenses', 20),\n    ('Housing', 'Home-related expenses including rent and utilities', 30),\n    ('Transportation', 'Public and private transportation costs', 40),\n    ('Vehicle', 'Car and vehicle related expenses', 50),\n    ('Life & Entertainment', 'Leisure activities and entertainment', 60),\n    ('Communication, PC', 'Internet, phone and computer expenses', 70),\n    ('Financial expenses', 'Banking fees, loans, and financial costs', 80),\n    ('Investments', 'Investment-related transactions', 90),\n    ('Income', 'All sources of incoming money', 100),\n    ('TRANSFER', 'Money transfers between accounts', 110)\n]\n\ncursor.executemany('INSERT OR IGNORE INTO categories (name, description, display_order) VALUES (?, ?, ?)', categories)\n\n# Insert subcategories for Food & Beverages\nfood_subcategories = [\n    (1, 'Bar, cafe, drink, snacks', 10),\n    (1, 'Groceries', 20),\n    (1, 'Restaurant, fast-food', 30)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', food_subcategories)\n\n# Insert subcategories for Shopping\nshopping_subcategories = [\n    (2, 'Clothes & Footwear', 10),\n    (2, 'Drug-store, chemist', 20),\n    (2, 'Electronics, accessories', 30),\n    (2, 'Gifts, joy', 40),\n    (2, 'Health and beauty', 50),\n    (2, 'Home, garden', 60),\n    (2, 'Jewels, accessories', 70),\n    (2, 'Kids', 80),\n    (2, 'Leisure time', 90),\n    (2, 'Pets, animals', 100),\n    (2, 'Stationery, tools', 110)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', shopping_subcategories)\n\nhousing_subcategories=[\n    (3, 'Energy, utilities', 10),\n    (3, 'Maintenance, repairs', 20),\n    (3, 'Mortgage', 30),\n    (3, 'Property insurance', 40),\n    (3, 'Rent', 50),\n    (3, 'Services', 60)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', housing_subcategories)\n\n\ntransportation_subcategories=[\n    (4, 'Business trips', 10),\n    (4, 'Long distance', 20),\n    (4, 'Public transport', 30),\n    (4, 'Taxi', 40)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', transportation_subcategories)\n\nvehicle_subcategories=[\n    (5, 'Fuel', 10),\n    (5, 'Leasing', 20),\n    (5, 'Parking', 30),\n    (5, 'Rentals', 40),\n    (5, 'Vehicle insurance', 50),\n    (5, 'Vehicle maintenance', 60)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', vehicle_subcategories)\n\nlife_subcategories=[\n    (6, 'Active sport, fitness', 10),\n    (6, 'Alcohol, tobacco', 20),\n    (6, 'Books, audio, subscriptions', 30),\n    (6, 'Charity, gifts', 40),\n    (6, 'Culture, sport events', 50),\n    (6, 'Education, development', 60),\n    (6, 'Health care, doctor', 70),\n    (6, 'Hobbies', 80),\n    (6, 'Holiday, trips, hotels', 90),\n    (6, 'Life events', 100),\n    (6, 'Lottery, gambling', 110),\n    (6, 'TV, Streaming', 120),\n    (6, 'Wellness, beauty', 130)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', life_subcategories)\n\ncommunication_subcategories=[\n    (7, 'Internet', 10),\n    (7, 'Postal services', 20),\n    (7, 'Software, apps, games', 30),\n    (7, 'Telephony, mobile phone', 40)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', communication_subcategories)\n\nfinancial_subcategories=[\n    (8, 'Advisory', 10),\n    (8, 'Charges, Fees', 20),\n    (8, 'Child Support', 30),\n    (8, 'Fines', 40),\n    (8, 'Insurances', 50),\n    (8, 'Loans, interests', 60),\n    (8, 'Taxes', 70)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', financial_subcategories)\n\ninvestments_subcategories=[\n    (9, 'Collections', 10),\n    (9, 'Financial investments', 20),\n    (9, 'Realty', 30),\n    (9, 'Savings', 40),\n    (9, 'Vehicles, chattels', 50)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', investments_subcategories)\n\nincome_subcategories=[\n    (10, 'Checks, coupons', 10),\n    (10, 'Child Support', 20),\n    (10, 'Dues & grants', 30),\n    (10, 'Gifts', 40),\n    (10, 'Interests, dividends', 50),\n    (10, 'Lending, renting', 60),\n    (10, 'Lottery earning', 70),\n    (10, 'Refunds (tax, purchase)', 80),\n    (10, 'Rental income', 90),\n    (10, 'Sale', 100),\n    (10, 'Wage, invoices', 110)\n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', income_subcategories)\n\ntransfer_subcatgories=[\n    (11, 'TRANSFER', 10),   \n]\ncursor.executemany('INSERT OR IGNORE INTO subcategories (category_id, name, display_order) VALUES (?, ?, ?)', transfer_subcatgories)\n\n# Commit the changes\ndb_conn.commit()\nprint(\"Database schema created successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.603991Z","iopub.status.idle":"2025-04-13T22:04:48.604349Z","shell.execute_reply.started":"2025-04-13T22:04:48.604182Z","shell.execute_reply":"2025-04-13T22:04:48.604200Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In this step, I create the mapping beween category and subcategory","metadata":{}},{"cell_type":"code","source":"def setup_database_and_get_hierarchy(output_path=\"/kaggle/working/category_mapping.csv\"):\n    \"\"\"\n    Initialize database, return category hierarchy, and output a simple mapping CSV.\n    \n    Args:\n        output_path: Path to save the mapping CSV\n        \n    Returns:\n        tuple: (db_connection, category_hierarchy_dict, subcategory_to_category_mapping)\n    \"\"\"\n    import sqlite3\n    import pandas as pd\n    \n    print(\"Setting up database and extracting category hierarchy...\")\n    \n    # Create database connection\n    db_conn = sqlite3.connect('/kaggle/working/transaction_categories.db')\n    cursor = db_conn.cursor()\n    \n    # Create tables and populate data if needed (your existing code)\n    # ... (Keep your existing table creation and population code)\n    \n    # Get complete hierarchy in one operation\n    cursor.execute(\"\"\"\n    SELECT \n        c.name as category, \n        s.name as subcategory\n    FROM categories c\n    JOIN subcategories s ON c.category_id = s.category_id\n    ORDER BY c.display_order, s.display_order\n    \"\"\")\n    \n    # Convert query results to DataFrame\n    results = cursor.fetchall()\n    mapping_df = pd.DataFrame(results, columns=['category', 'subcategory'])\n    \n    # Process results into usable format for return values\n    category_hierarchy = {}\n    subcat_to_cat_mapping = {}\n    \n    for category, subcategory in results:\n        # Build hierarchy dictionary\n        if category not in category_hierarchy:\n            category_hierarchy[category] = []\n        category_hierarchy[category].append(subcategory)\n        \n        # Build mapping dictionary\n        subcat_to_cat_mapping[subcategory] = category\n    \n    # Save to CSV file\n    mapping_df.to_csv(output_path, index=False)\n    \n    # Print summary\n    print(f\"\\nCategory-subcategory mapping saved to {output_path}\")\n    print(f\"Found {len(mapping_df['category'].unique())} categories and {len(mapping_df)} subcategories\")\n    print(\"\\nSample of mapping:\")\n    print(mapping_df.head(5))\n    \n    db_conn.commit()\n    \n    return db_conn, category_hierarchy, subcat_to_cat_mapping","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.606976Z","iopub.execute_input":"2025-04-13T22:04:48.607279Z","iopub.status.idle":"2025-04-13T22:04:48.615187Z","shell.execute_reply.started":"2025-04-13T22:04:48.607248Z","shell.execute_reply":"2025-04-13T22:04:48.614120Z"}},"outputs":[],"execution_count":103},{"cell_type":"markdown","source":"## Load the dataset\n\nI have uploaded transaction data categorised by me. Then I group it into training data and test data.","metadata":{"id":"peFm0w_0c1CO"}},{"cell_type":"code","source":"# Load and preprocess transaction data\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Load your data\nfile_path = \"/kaggle/input/training/categorized_transaction.csv\"\ndf = pd.read_csv(file_path)\n\n# Split into train and test sets (80/20 split)\ndf_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n\n# Display the subcategories (labels) in your dataset\nsubcategories = df['subcategory'].unique()\nprint(f\"Number of subcategories: {len(subcategories)}\")\nprint(\"Sample subcategories:\", subcategories[:10])  # Show first 10 subcategories\n\n# Quick look at note examples\nprint(\"\\nSample notes:\")\nfor i, note in enumerate(df['note'].head(3)):\n    print(f\"{i+1}. {note} → {df['subcategory'].iloc[i]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.724275Z","iopub.execute_input":"2025-04-13T22:04:48.724657Z","iopub.status.idle":"2025-04-13T22:04:48.775619Z","shell.execute_reply.started":"2025-04-13T22:04:48.724617Z","shell.execute_reply":"2025-04-13T22:04:48.774643Z"}},"outputs":[{"name":"stdout","text":"Number of subcategories: 64\nSample subcategories: ['Active sport, fitness' 'Advisory' 'Alcohol, tobacco'\n 'Bar, cafe, drink, snacks' 'Books, audio, subscriptions' 'Charges, Fees'\n 'Charity, gifts' 'Checks, coupons' 'Clothes & shoes'\n 'Culture, sport events']\n\nSample notes:\n1. AMAZON AUSYDNEY SOUTH CREDIT CARD PURCHASEAmazon Basics High-Density Round Foam Roller for Exercise and Recovery - 61cm, Blue Speckled → Active sport, fitness\n2. 02 DEC 20 - $98.00 LULULEMON ATHLETICA AUSTRAlbert Park [Eff Date: 30 NOV 20] → Active sport, fitness\n3. REBEL MELBOURNE CTRL MELBOURNE VI AUSTap and Pay xx3173Value Date_ 17/03/2018 → Active sport, fitness\n","output_type":"stream"}],"execution_count":104},{"cell_type":"markdown","source":"## Clean the data","metadata":{}},{"cell_type":"code","source":"import re\nimport pandas as pd\n\ndef clean_transaction_note(note):\n    \"\"\"\n    Clean transaction notes to remove common bank formatting, dates, card numbers, etc.\n    \"\"\"\n    # Handle None or empty strings\n    if note is None or pd.isna(note) or note == \"\":\n        return \"\"\n    \n    # Convert to string if needed\n    text = str(note)\n    \n    # Replace non-ASCII characters\n    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n    \n    # Extract main part of the transaction (before common transaction markers)\n    transaction_markers = r'\\s+(?:CREDIT CARD PURCHASE|EFTPOS|Value Date|tap and Pay|Card Purchase|CARD PURCHASE)'\n    parts = re.split(transaction_markers, text, flags=re.IGNORECASE)\n    main_text = parts[0] if parts else text\n    \n    # Clean amount figures and currency symbols\n    main_text = re.sub(r'(?:[$€£¥]|AUD|USD|EUR|GBP|NZD)\\s*[-+]?(?:\\d{1,3}(?:,\\d{3})*|\\d+)(?:\\.\\d{1,2})?', '', main_text)\n    main_text = re.sub(r'\\b[-+]?(?:\\d{1,3}(?:,\\d{3})*|\\d+)(?:\\.\\d{1,2})?\\b', '', main_text)\n    \n    # Remove card numbers (masked or full)\n    main_text = re.sub(r'(?:x{2,4}|X{2,4})\\d{4}|\\b\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}[\\s-]?\\d{4}\\b', '', main_text)\n    \n    # Remove date patterns\n    date_pattern = r'(?:\\d{1,2}\\s+(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{2,4}|' + \\\n                   r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*\\s+\\d{1,2}(?:st|nd|rd|th)?\\s+\\d{2,4}|' + \\\n                   r'\\d{1,2}[-/.]\\d{1,2}[-/.]\\d{2,4}|' + \\\n                   r'\\d{4}[-/.]\\d{1,2}[-/.]\\d{1,2}|' + \\\n                   r'\\[Eff\\s+Date:.*?\\]|' + \\\n                   r'Value\\s+Date[_:]\\s*\\d{1,2}[-/.]\\d{1,2}[-/.]\\d{2,4})'\n    main_text = re.sub(date_pattern, '', main_text, flags=re.IGNORECASE)\n    \n    # Clean whitespace and punctuation\n    main_text = re.sub(r'\\s+', ' ', main_text)\n    main_text = re.sub(r'[\\s,.-]+$|^[\\s,.-]+', '', main_text)\n    main_text = re.sub(r'\\s+([,.])', r'\\1', main_text)\n    \n    return main_text.strip()[:500]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.777374Z","iopub.execute_input":"2025-04-13T22:04:48.777701Z","iopub.status.idle":"2025-04-13T22:04:48.785608Z","shell.execute_reply.started":"2025-04-13T22:04:48.777669Z","shell.execute_reply":"2025-04-13T22:04:48.784581Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"def add_category_column(df, db_conn):\n    \"\"\"\n    Add category column to DataFrame based on subcategory using database mapping.\n    \"\"\"\n    if 'category' in df.columns:\n        print(\"Category column already exists\")\n        return df\n    \n    try:\n        # Query the database for subcategory to category mapping\n        cursor = db_conn.cursor()\n        cursor.execute(\"\"\"\n        SELECT s.name as subcategory, c.name as category \n        FROM subcategories s\n        JOIN categories c ON s.category_id = c.category_id\n        \"\"\")\n        \n        # Create mapping dictionary\n        subcat_to_cat = {row[0]: row[1] for row in cursor.fetchall()}\n        \n        # Add category column\n        df_with_category = df.copy()\n        df_with_category['category'] = df['subcategory'].map(subcat_to_cat)\n        \n        # Check for unmapped subcategories\n        missing_count = df_with_category['category'].isna().sum()\n        if missing_count > 0:\n            print(f\"Warning: {missing_count} rows have unmapped subcategories\")\n            unmapped = df[df['subcategory'].map(lambda x: x not in subcat_to_cat)]['subcategory'].unique()\n            print(f\"Unmapped subcategories: {unmapped}\")\n            \n        # Fill missing with placeholder\n        df_with_category['category'] = df_with_category['category'].fillna(\"Unknown\")\n        \n        print(f\"Added categories to {len(df_with_category)} transactions\")\n        return df_with_category\n        \n    except Exception as e:\n        print(f\"Error getting category mapping: {e}\")\n        # Create placeholder category column if needed\n        df_copy = df.copy()\n        df_copy['category'] = \"Unknown\"\n        return df_copy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.786989Z","iopub.execute_input":"2025-04-13T22:04:48.787372Z","iopub.status.idle":"2025-04-13T22:04:48.795776Z","shell.execute_reply.started":"2025-04-13T22:04:48.787329Z","shell.execute_reply":"2025-04-13T22:04:48.794869Z"}},"outputs":[],"execution_count":106},{"cell_type":"code","source":"def sample_balanced_data(df, samples_per_subcategory):\n    \"\"\"\n    Create a balanced dataset by sampling evenly across subcategories.\n    If a subcategory has fewer than the requested samples, uses all available rows.\n    \"\"\"\n    # Group by subcategory and sample\n    sampled_df = (\n        df.groupby(\"subcategory\")[df.columns]\n        .apply(lambda x: x.sample(min(len(x), samples_per_subcategory)))\n        .reset_index(drop=True)\n    )\n    \n    # Convert subcategory to category type for efficiency\n    sampled_df[\"subcategory\"] = sampled_df[\"subcategory\"].astype(\"category\")\n    \n    return sampled_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.797722Z","iopub.execute_input":"2025-04-13T22:04:48.798011Z","iopub.status.idle":"2025-04-13T22:04:48.803183Z","shell.execute_reply.started":"2025-04-13T22:04:48.797983Z","shell.execute_reply":"2025-04-13T22:04:48.802304Z"}},"outputs":[],"execution_count":107},{"cell_type":"code","source":"def filter_unmapped_subcategories(df, db_conn):\n    \"\"\"\n    Filter out rows with subcategories that don't have a mapping in the database.\n    \n    Args:\n        df: DataFrame containing transaction data\n        db_conn: Database connection\n        \n    Returns:\n        DataFrame with only mapped subcategories\n    \"\"\"\n    # Get all valid subcategories from the database\n    cursor = db_conn.cursor()\n    cursor.execute(\"SELECT name FROM subcategories\")\n    valid_subcategories = [row[0] for row in cursor.fetchall()]\n    \n    # Filter the DataFrame to only include rows with valid subcategories\n    df_filtered = df[df['subcategory'].isin(valid_subcategories)].copy()\n    \n    # Report how many rows were filtered out\n    filtered_count = len(df) - len(df_filtered)\n    print(f\"Filtered out {filtered_count} rows with unmapped subcategories\")\n    print(f\"Unmapped subcategories: {df[~df['subcategory'].isin(valid_subcategories)]['subcategory'].unique()}\")\n    \n    return df_filtered","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.804321Z","iopub.execute_input":"2025-04-13T22:04:48.804584Z","iopub.status.idle":"2025-04-13T22:04:48.810199Z","shell.execute_reply.started":"2025-04-13T22:04:48.804556Z","shell.execute_reply":"2025-04-13T22:04:48.809262Z"}},"outputs":[],"execution_count":108},{"cell_type":"code","source":"def process_transaction_data(df, db_conn, train_samples=50, test_samples=10, sample_csv_path=None):\n    \"\"\"\n    Process transaction data through all steps: cleaning, categorizing, sampling, and filtering unmapped subcategories.\n    \n    Args:\n        df: DataFrame with transaction data\n        db_conn: Database connection for category mapping\n        train_samples: Number of samples per subcategory for training\n        test_samples: Number of samples per subcategory for testing\n        sample_csv_path: Path to save a sample CSV for review\n        \n    Returns:\n        Tuple of (train_df, test_df, df_with_categories)\n    \"\"\"\n    # Make a copy to avoid modifying the original\n    df_copy = df.copy()\n    \n    # Step 1: Clean transaction notes\n    print(\"Cleaning transaction notes...\")\n    df_copy['cleaned_note'] = df_copy['note'].apply(clean_transaction_note)\n    \n    # Step 2: Add category column\n    print(\"Adding category mapping...\")\n    df_with_categories = add_category_column(df_copy, db_conn)\n    \n    # Step 3: Filter out unmapped subcategories\n    print(\"Filtering out unmapped subcategories...\")\n    df_filtered = filter_unmapped_subcategories(df_with_categories, db_conn)\n    \n    # Step 4: Split into train and test data\n    train_df, test_df = train_test_split(df_filtered, test_size=0.2, random_state=42)\n    \n    # Step 5: Sample balanced datasets\n    print(f\"Creating balanced samples ({train_samples} per subcategory for training)...\")\n    train_sampled = sample_balanced_data(train_df, train_samples)\n    test_sampled = sample_balanced_data(test_df, test_samples)\n    \n    # Step 6: Save sample for review if requested\n    if sample_csv_path:\n        # Take a small sample from each subcategory for review\n        review_sample = sample_balanced_data(df_filtered, 2)\n        # Include original and cleaned notes for comparison\n        review_sample = review_sample[['note', 'cleaned_note', 'category', 'subcategory']]\n        review_sample.to_csv(sample_csv_path, index=False)\n        print(f\"Saved sample data to {sample_csv_path} for review\")\n    \n    # Print statistics\n    print(f\"Original data: {len(df)} transactions\")\n    print(f\"Filtered data: {len(df_filtered)} transactions\")\n    print(f\"Balanced training data: {len(train_sampled)} transactions ({train_sampled['subcategory'].nunique()} subcategories)\")\n    print(f\"Balanced test data: {len(test_sampled)} transactions ({test_sampled['subcategory'].nunique()} subcategories)\")\n    \n    return train_sampled, test_sampled, df_filtered","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.811440Z","iopub.execute_input":"2025-04-13T22:04:48.811721Z","iopub.status.idle":"2025-04-13T22:04:48.819161Z","shell.execute_reply.started":"2025-04-13T22:04:48.811693Z","shell.execute_reply":"2025-04-13T22:04:48.818286Z"}},"outputs":[],"execution_count":109},{"cell_type":"markdown","source":"## Sample the dataset\nNow sample the data. I will keep 50 rows for each subcategory for training.","metadata":{"id":"03lDs1O4ZQ0-"}},{"cell_type":"code","source":"# Connect to the database\nimport sqlite3\nimport pandas as pd\nfrom collections import Counter\n\ndb_conn = sqlite3.connect('/kaggle/working/transaction_categories.db')\n\n# Process the data\ndf_train_sampled, df_test_sampled, df_categorized = process_transaction_data(\n    df, \n    db_conn,\n    train_samples=50, \n    test_samples=10,\n    sample_csv_path=\"/kaggle/working/transaction_sample_review.csv\"\n)\n\n# Print distribution of categories and subcategories\ndef print_distribution_stats(df, dataset_name=\"Dataset\"):\n    print(f\"\\n{'-'*50}\")\n    print(f\"{dataset_name} Distribution Statistics:\")\n    print(f\"{'-'*50}\")\n    \n    # Category distribution\n    category_counts = df['category'].value_counts()\n    print(f\"\\nCategories ({len(category_counts)} unique):\")\n    print(f\"{'Category':<25} {'Count':<10} {'Percentage':<10}\")\n    print(f\"{'-'*45}\")\n    \n    for category, count in category_counts.items():\n        percentage = count / len(df) * 100\n        print(f\"{category[:25]:<25} {count:<10} {percentage:.1f}%\")\n    \n    # Subcategory distribution\n    subcategory_counts = df['subcategory'].value_counts()\n    print(f\"\\nSubcategories ({len(subcategory_counts)} unique):\")\n    print(f\"{'Subcategory':<30} {'Category':<20} {'Count':<10} {'Percentage':<10}\")\n    print(f\"{'-'*70}\")\n    \n    # Create a mapping from subcategory to category for lookup\n    subcat_to_cat = df.groupby('subcategory')['category'].first().to_dict()\n    \n    for subcategory, count in subcategory_counts.items():\n        percentage = count / len(df) * 100\n        category = subcat_to_cat.get(subcategory, \"Unknown\")\n        print(f\"{subcategory[:30]:<30} {category[:20]:<20} {count:<10} {percentage:.1f}%\")\n    \n    # Find subcategories with low counts (potential data issues)\n    low_count_threshold = 5  # Adjust as needed\n    low_count_subcats = subcategory_counts[subcategory_counts < low_count_threshold]\n    if len(low_count_subcats) > 0:\n        print(f\"\\nSubcategories with low counts (<{low_count_threshold}):\")\n        for subcat, count in low_count_subcats.items():\n            print(f\"  - {subcat}: {count} transactions\")\n\n# Display sample of training data\nprint(\"\\nSample of training data:\")\nprint(df_train_sampled[['cleaned_note', 'category', 'subcategory']].head())\n\n# Print distribution statistics for both datasets\nprint_distribution_stats(df_train_sampled, \"Training Data\")\nprint_distribution_stats(df_test_sampled, \"Test Data\")\n\n# Additional summary statistics\nprint(f\"\\n{'-'*50}\")\nprint(f\"Summary Statistics:\")\nprint(f\"{'-'*50}\")\nprint(f\"Total transactions in original data: {len(df)}\")\nprint(f\"Total transactions in training data: {len(df_train_sampled)}\")\nprint(f\"Total transactions in test data: {len(df_test_sampled)}\")\nprint(f\"Training data categories: {df_train_sampled['category'].nunique()}\")\nprint(f\"Test data categories: {df_test_sampled['category'].nunique()}\")\nprint(f\"Training data subcategories: {df_train_sampled['subcategory'].nunique()}\")\nprint(f\"Test data subcategories: {df_test_sampled['subcategory'].nunique()}\")\n\n# Check for any subcategories in test but not in training\ntrain_subcats = set(df_train_sampled['subcategory'].unique())\ntest_subcats = set(df_test_sampled['subcategory'].unique())\ntest_only_subcats = test_subcats - train_subcats\n\nif test_only_subcats:\n    print(f\"\\nWarning: {len(test_only_subcats)} subcategories in test data but not in training data:\")\n    for subcat in test_only_subcats:\n        print(f\"  - {subcat}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:48.820325Z","iopub.execute_input":"2025-04-13T22:04:48.820607Z","iopub.status.idle":"2025-04-13T22:04:49.341294Z","shell.execute_reply.started":"2025-04-13T22:04:48.820560Z","shell.execute_reply":"2025-04-13T22:04:49.340310Z"}},"outputs":[{"name":"stdout","text":"Cleaning transaction notes...\nAdding category mapping...\nWarning: 377 rows have unmapped subcategories\nUnmapped subcategories: ['Clothes & shoes' 'Financial expenses' 'Food & Drinks' 'Free time'\n 'Housing' 'Life & Entertainment' 'Loan, interests' 'Missing' 'Others'\n 'Phone, cell phone' 'Shopping' 'Transportation']\nAdded categories to 12388 transactions\nFiltering out unmapped subcategories...\nFiltered out 377 rows with unmapped subcategories\nUnmapped subcategories: ['Clothes & shoes' 'Financial expenses' 'Food & Drinks' 'Free time'\n 'Housing' 'Life & Entertainment' 'Loan, interests' 'Missing' 'Others'\n 'Phone, cell phone' 'Shopping' 'Transportation']\nCreating balanced samples (50 per subcategory for training)...\nSaved sample data to /kaggle/working/transaction_sample_review.csv for review\nOriginal data: 12388 transactions\nFiltered data: 12011 transactions\nBalanced training data: 1467 transactions (52 subcategories)\nBalanced test data: 311 transactions (45 subcategories)\n\nSample of training data:\n                                        cleaned_note              category  \\\n0         DEC - LULULEMON ATHLETICA AUSTRAlbert Park  Life & Entertainment   \n1  REBEL MELBOURNE CTRL MELBOURNE VI AUSTap and P...  Life & Entertainment   \n2  STATE TRUSTEES LIMIT MELBOURNE AUSCard Value D...    Financial expenses   \n3                       LIQUORLAND EASTLAND RINGWOOD  Life & Entertainment   \n4                              BWS HWATHORN HWATHORN  Life & Entertainment   \n\n             subcategory  \n0  Active sport, fitness  \n1  Active sport, fitness  \n2               Advisory  \n3       Alcohol, tobacco  \n4       Alcohol, tobacco  \n\n--------------------------------------------------\nTraining Data Distribution Statistics:\n--------------------------------------------------\n\nCategories (11 unique):\nCategory                  Count      Percentage\n---------------------------------------------\nLife & Entertainment      375        25.6%\nShopping                  261        17.8%\nHousing                   160        10.9%\nIncome                    157        10.7%\nFood & Beverages          150        10.2%\nCommunication, PC         102        7.0%\nTransportation            83         5.7%\nFinancial expenses        63         4.3%\nTRANSFER                  50         3.4%\nInvestments               47         3.2%\nVehicle                   19         1.3%\n\nSubcategories (52 unique):\nSubcategory                    Category             Count      Percentage\n----------------------------------------------------------------------\nInterests, dividends           Income               50         3.4%\nSoftware, apps, games          Communication, PC    50         3.4%\nHome, garden                   Shopping             50         3.4%\nHealth and beauty              Shopping             50         3.4%\nGroceries                      Food & Beverages     50         3.4%\nInternet                       Communication, PC    50         3.4%\nMaintenance, repairs           Housing              50         3.4%\nPublic transport               Transportation       50         3.4%\nRefunds (tax, purchase)        Income               50         3.4%\nEnergy, utilities              Housing              50         3.4%\nRestaurant, fast-food          Food & Beverages     50         3.4%\nDrug-store, chemist            Shopping             50         3.4%\nTRANSFER                       TRANSFER             50         3.4%\nTV, Streaming                  Life & Entertainment 50         3.4%\nCharity, gifts                 Life & Entertainment 50         3.4%\nCharges, Fees                  Financial expenses   50         3.4%\nBooks, audio, subscriptions    Life & Entertainment 50         3.4%\nBar, cafe, drink, snacks       Food & Beverages     50         3.4%\nWage, invoices                 Income               50         3.4%\nHobbies                        Life & Entertainment 50         3.4%\nFinancial investments          Investments          46         3.1%\nElectronics, accessories       Shopping             44         3.0%\nHoliday, trips, hotels         Life & Entertainment 43         2.9%\nWellness, beauty               Life & Entertainment 41         2.8%\nGifts, joy                     Shopping             37         2.5%\nRent                           Housing              36         2.5%\nEducation, development         Life & Entertainment 34         2.3%\nTaxi                           Transportation       32         2.2%\nStationery, tools              Shopping             26         1.8%\nCulture, sport events          Life & Entertainment 21         1.4%\nServices                       Housing              18         1.2%\nHealth care, doctor            Life & Entertainment 14         1.0%\nLife events                    Life & Entertainment 12         0.8%\nInsurances                     Financial expenses   11         0.7%\nRentals                        Vehicle              11         0.7%\nParking                        Vehicle              6          0.4%\nMortgage                       Housing              6          0.4%\nGifts                          Income               5          0.3%\nLottery, gambling              Life & Entertainment 4          0.3%\nAlcohol, tobacco               Life & Entertainment 4          0.3%\nJewels, accessories            Shopping             3          0.2%\nActive sport, fitness          Life & Entertainment 2          0.1%\nPostal services                Communication, PC    2          0.1%\nSavings                        Investments          1          0.1%\nFuel                           Vehicle              1          0.1%\nDues & grants                  Income               1          0.1%\nPets, animals                  Shopping             1          0.1%\nChecks, coupons                Income               1          0.1%\nLong distance                  Transportation       1          0.1%\nVehicle insurance              Vehicle              1          0.1%\nAdvisory                       Financial expenses   1          0.1%\nFines                          Financial expenses   1          0.1%\n\nSubcategories with low counts (<5):\n  - Lottery, gambling: 4 transactions\n  - Alcohol, tobacco: 4 transactions\n  - Jewels, accessories: 3 transactions\n  - Active sport, fitness: 2 transactions\n  - Postal services: 2 transactions\n  - Savings: 1 transactions\n  - Fuel: 1 transactions\n  - Dues & grants: 1 transactions\n  - Pets, animals: 1 transactions\n  - Checks, coupons: 1 transactions\n  - Long distance: 1 transactions\n  - Vehicle insurance: 1 transactions\n  - Advisory: 1 transactions\n  - Fines: 1 transactions\n\n--------------------------------------------------\nTest Data Distribution Statistics:\n--------------------------------------------------\n\nCategories (11 unique):\nCategory                  Count      Percentage\n---------------------------------------------\nLife & Entertainment      90         28.9%\nShopping                  55         17.7%\nIncome                    35         11.3%\nHousing                   33         10.6%\nFood & Beverages          30         9.6%\nCommunication, PC         21         6.8%\nTransportation            18         5.8%\nFinancial expenses        14         4.5%\nTRANSFER                  10         3.2%\nInvestments               3          1.0%\nVehicle                   2          0.6%\n\nSubcategories (45 unique):\nSubcategory                    Category             Count      Percentage\n----------------------------------------------------------------------\nWellness, beauty               Life & Entertainment 10         3.2%\nTRANSFER                       TRANSFER             10         3.2%\nRestaurant, fast-food          Food & Beverages     10         3.2%\nMaintenance, repairs           Housing              10         3.2%\nSoftware, apps, games          Communication, PC    10         3.2%\nInternet                       Communication, PC    10         3.2%\nInterests, dividends           Income               10         3.2%\nHome, garden                   Shopping             10         3.2%\nHoliday, trips, hotels         Life & Entertainment 10         3.2%\nHobbies                        Life & Entertainment 10         3.2%\nHealth and beauty              Shopping             10         3.2%\nPublic transport               Transportation       10         3.2%\nGroceries                      Food & Beverages     10         3.2%\nEnergy, utilities              Housing              10         3.2%\nDrug-store, chemist            Shopping             10         3.2%\nWage, invoices                 Income               10         3.2%\nBar, cafe, drink, snacks       Food & Beverages     10         3.2%\nBooks, audio, subscriptions    Life & Entertainment 10         3.2%\nCharges, Fees                  Financial expenses   10         3.2%\nCharity, gifts                 Life & Entertainment 10         3.2%\nRefunds (tax, purchase)        Income               10         3.2%\nTV, Streaming                  Life & Entertainment 10         3.2%\nEducation, development         Life & Entertainment 10         3.2%\nElectronics, accessories       Shopping             10         3.2%\nGifts, joy                     Shopping             9          2.9%\nRent                           Housing              9          2.9%\nTaxi                           Transportation       8          2.6%\nHealth care, doctor            Life & Entertainment 7          2.3%\nLife events                    Life & Entertainment 5          1.6%\nGifts                          Income               4          1.3%\nStationery, tools              Shopping             4          1.3%\nServices                       Housing              3          1.0%\nInsurances                     Financial expenses   3          1.0%\nLottery, gambling              Life & Entertainment 3          1.0%\nFinancial investments          Investments          3          1.0%\nCulture, sport events          Life & Entertainment 3          1.0%\nRentals                        Vehicle              2          0.6%\nPostal services                Communication, PC    1          0.3%\nPets, animals                  Shopping             1          0.3%\nMortgage                       Housing              1          0.3%\nJewels, accessories            Shopping             1          0.3%\nAdvisory                       Financial expenses   1          0.3%\nDues & grants                  Income               1          0.3%\nAlcohol, tobacco               Life & Entertainment 1          0.3%\nActive sport, fitness          Life & Entertainment 1          0.3%\n\nSubcategories with low counts (<5):\n  - Gifts: 4 transactions\n  - Stationery, tools: 4 transactions\n  - Services: 3 transactions\n  - Insurances: 3 transactions\n  - Lottery, gambling: 3 transactions\n  - Financial investments: 3 transactions\n  - Culture, sport events: 3 transactions\n  - Rentals: 2 transactions\n  - Postal services: 1 transactions\n  - Pets, animals: 1 transactions\n  - Mortgage: 1 transactions\n  - Jewels, accessories: 1 transactions\n  - Advisory: 1 transactions\n  - Dues & grants: 1 transactions\n  - Alcohol, tobacco: 1 transactions\n  - Active sport, fitness: 1 transactions\n\n--------------------------------------------------\nSummary Statistics:\n--------------------------------------------------\nTotal transactions in original data: 12388\nTotal transactions in training data: 1467\nTotal transactions in test data: 311\nTraining data categories: 11\nTest data categories: 11\nTraining data subcategories: 52\nTest data subcategories: 45\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/2278908751.py:40: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  subcat_to_cat = df.groupby('subcategory')['category'].first().to_dict()\n/tmp/ipykernel_30/2278908751.py:40: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  subcat_to_cat = df.groupby('subcategory')['category'].first().to_dict()\n","output_type":"stream"}],"execution_count":110},{"cell_type":"markdown","source":"## Instruct the zero-shot prompt\nI draft the prompt asking it to only use the subcategory from the loaded table.","metadata":{}},{"cell_type":"code","source":" import sqlite3\n\ndb_file = \"transaction_categories.db\"\ndb_conn = sqlite3.connect(db_file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:49.342457Z","iopub.execute_input":"2025-04-13T22:04:49.342757Z","iopub.status.idle":"2025-04-13T22:04:49.347377Z","shell.execute_reply.started":"2025-04-13T22:04:49.342727Z","shell.execute_reply":"2025-04-13T22:04:49.346382Z"}},"outputs":[],"execution_count":111},{"cell_type":"code","source":"def predict_category_and_subcategory(transaction_note):\n    \"\"\"\n    Predicts the category and subcategory for a transaction using the zero-shot system instruction approach.\n    Ensures that the subcategory belongs to the selected category based on database mappings.\n    \n    Args:\n        transaction_note: The transaction text to classify\n        \n    Returns:\n        tuple: (predicted_category, predicted_subcategory)\n    \"\"\"\n    try:\n        system_instruct = \"\"\"\n        You are a financial transaction categorization assistant. You will analyze a transaction description and classify it into the appropriate category and subcategory.\n\n        Follow these steps exactly:\n        1. First, select the most appropriate CATEGORY from the available options\n        2. Then, select a SUBCATEGORY that belongs to the selected CATEGORY\n\n        Important: You must ensure the subcategory you select belongs to the category you chose. The database has specific parent-child relationships between categories and subcategories.\n\n        Your response must use this exact format:\n        CATEGORY: [selected category name]\n        SUBCATEGORY: [selected subcategory name]\n        \"\"\"\n        \n        # First, get all category-subcategory mappings from the database to provide context\n        cursor = db_conn.cursor()\n        cursor.execute(\"\"\"\n        SELECT c.name as category, s.name as subcategory \n        FROM categories c\n        JOIN subcategories s ON c.category_id = s.category_id\n        ORDER BY c.name, s.name\n        \"\"\")\n        mappings = cursor.fetchall()\n        \n        # Create context about the hierarchical structure\n        hierarchy_context = \"Category and subcategory hierarchy from the database:\\n\"\n        current_category = None\n        for category, subcategory in mappings:\n            if category != current_category:\n                hierarchy_context += f\"\\n{category}:\\n\"\n                current_category = category\n            hierarchy_context += f\"  - {subcategory}\\n\"\n        \n        # Make prediction with system instruction and hierarchy context\n        response = client.models.generate_content(\n            model=\"gemini-2.0-flash\",\n            config=types.GenerateContentConfig(\n                system_instruction=system_instruct,\n                temperature=0.2,  # Lower temperature for more consistent results\n            ),\n            contents=[\n                hierarchy_context,\n                f\"Transaction description: {transaction_note}\\n\\nPlease categorize this transaction:\"\n            ]\n        )\n        \n        text = response.text.strip()\n        \n        # Extract category and subcategory\n        try:\n            category_line = [line for line in text.split('\\n') if line.startswith(\"CATEGORY:\")][0]\n            subcategory_line = [line for line in text.split('\\n') if line.startswith(\"SUBCATEGORY:\")][0]\n            \n            category = category_line.replace(\"CATEGORY:\", \"\").strip()\n            subcategory = subcategory_line.replace(\"SUBCATEGORY:\", \"\").strip()\n            \n            # Verify that the subcategory belongs to the category using the database\n            cursor.execute(\"\"\"\n            SELECT COUNT(*) FROM subcategories s\n            JOIN categories c ON s.category_id = c.category_id\n            WHERE c.name = ? AND s.name = ?\n            \"\"\", (category, subcategory))\n            \n            count = cursor.fetchone()[0]\n            if count == 0:\n                # If the model returned an invalid mapping, find a valid subcategory for the category\n                cursor.execute(\"\"\"\n                SELECT s.name FROM subcategories s\n                JOIN categories c ON s.category_id = c.category_id\n                WHERE c.name = ?\n                LIMIT 1\n                \"\"\", (category,))\n                \n                result = cursor.fetchone()\n                if result:\n                    # Use a valid subcategory for this category\n                    subcategory = result[0]\n                    return category, subcategory\n                else:\n                    # If category is invalid too, return error\n                    return \"(invalid category)\", \"(invalid subcategory)\"\n            \n            return category, subcategory\n            \n        except (IndexError, KeyError) as e:\n            return \"(parsing error)\", \"(parsing error)\"\n            \n    except Exception as e:\n        return f\"(error)\", f\"(error: {str(e)})\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:49.348940Z","iopub.execute_input":"2025-04-13T22:04:49.349195Z","iopub.status.idle":"2025-04-13T22:04:49.359577Z","shell.execute_reply.started":"2025-04-13T22:04:49.349169Z","shell.execute_reply":"2025-04-13T22:04:49.358657Z"}},"outputs":[],"execution_count":112},{"cell_type":"markdown","source":"## Evaluate baseline performance\n\nNow I perform an evaluation on the available models to ensure I can measure how much the tuning helps.","metadata":{}},{"cell_type":"code","source":"import tqdm\nfrom tqdm.rich import tqdm as tqdmr\nimport warnings\n\n# Enable tqdm features on Pandas\ntqdmr.pandas()\n\n# Suppress the experimental warning\nwarnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n\n# Further sample the test data to be mindful of the free-tier quota\nTEST_SAMPLE_SIZE = 20\ndf_baseline_eval = df_test_sampled.sample(min(TEST_SAMPLE_SIZE, len(df_test_sampled)))\n\n# Ensure category column exists in test data\nif 'category' not in df_baseline_eval.columns:\n    # Add categories using the database mapping\n    cursor = db_conn.cursor()\n    cursor.execute(\"\"\"\n    SELECT s.name as subcategory, c.name as category \n    FROM subcategories s\n    JOIN categories c ON s.category_id = c.category_id\n    \"\"\")\n    subcat_to_cat = {row[0]: row[1] for row in cursor.fetchall()}\n    df_baseline_eval['category'] = df_baseline_eval['subcategory'].map(subcat_to_cat)\n\nprint(f\"Evaluating {len(df_baseline_eval)} transactions...\")\n\n# Make predictions using the sampled data with progress bar\n# This will return both category and subcategory\ndf_baseline_eval[['predicted_category', 'predicted_subcategory']] = df_baseline_eval['note'].progress_apply(\n    lambda x: pd.Series(predict_category_and_subcategory(x))\n)\n\n# Calculate the accuracy for both category and subcategory\ncategory_accuracy = (df_baseline_eval['category'] == df_baseline_eval['predicted_category']).mean()\nsubcategory_accuracy = (df_baseline_eval['subcategory'] == df_baseline_eval['predicted_subcategory']).mean()\ncombined_accuracy = ((df_baseline_eval['category'] == df_baseline_eval['predicted_category']) & \n                     (df_baseline_eval['subcategory'] == df_baseline_eval['predicted_subcategory'])).mean()\n\nprint(f\"Category accuracy: {category_accuracy:.2%}\")\nprint(f\"Subcategory accuracy: {subcategory_accuracy:.2%}\")\nprint(f\"Combined accuracy (both correct): {combined_accuracy:.2%}\")\n\n# Display some examples of predictions\nprint(\"\\nSample predictions:\")\nsample_results = df_baseline_eval[['note', 'category', 'subcategory', \n                                  'predicted_category', 'predicted_subcategory']].sample(min(5, len(df_baseline_eval)))\n\nfor idx, row in sample_results.iterrows():\n    print(f\"Transaction: {row['note'][:50]}...\")\n    print(f\"True category: {row['category']}\")\n    print(f\"Predicted category: {row['predicted_category']}\")\n    print(f\"Category correct: {row['category'] == row['predicted_category']}\")\n    print(f\"True subcategory: {row['subcategory']}\")\n    print(f\"Predicted subcategory: {row['predicted_subcategory']}\")\n    print(f\"Subcategory correct: {row['subcategory'] == row['predicted_subcategory']}\\n\")\n\n# Create a confusion matrix for categories\nprint(\"Category confusion matrix:\")\ncat_matrix = pd.crosstab(\n    df_baseline_eval['category'], \n    df_baseline_eval['predicted_category'],\n    rownames=['True'], \n    colnames=['Predicted']\n)\nprint(cat_matrix)\n\n# Create a confusion matrix for subcategories with errors\nprint(\"\\nMost common subcategory error patterns:\")\nerror_patterns = df_baseline_eval[df_baseline_eval['subcategory'] != df_baseline_eval['predicted_subcategory']]\nif len(error_patterns) > 0:\n    error_counts = error_patterns.groupby(['subcategory', 'predicted_subcategory']).size().reset_index(name='count')\n    error_counts = error_counts.sort_values('count', ascending=False)\n    print(error_counts.head(5))\nelse:\n    print(\"No subcategory errors found in the evaluation set!\")\n\n# Analysis of hierarchical errors\nprint(\"\\nError analysis by hierarchy:\")\nhierarchical_errors = df_baseline_eval[\n    (df_baseline_eval['category'] == df_baseline_eval['predicted_category']) & \n    (df_baseline_eval['subcategory'] != df_baseline_eval['predicted_subcategory'])\n]\nprint(f\"Correct category but wrong subcategory: {len(hierarchical_errors)} cases ({len(hierarchical_errors)/len(df_baseline_eval):.2%})\")\n\ncategory_errors = df_baseline_eval[df_baseline_eval['category'] != df_baseline_eval['predicted_category']]\nprint(f\"Wrong category: {len(category_errors)} cases ({len(category_errors)/len(df_baseline_eval):.2%})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:04:49.362282Z","iopub.execute_input":"2025-04-13T22:04:49.362571Z","iopub.status.idle":"2025-04-13T22:05:02.893616Z","shell.execute_reply.started":"2025-04-13T22:04:49.362542Z","shell.execute_reply":"2025-04-13T22:05:02.892652Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2bcd13f0f84f088a460268d003f5d5"}},"metadata":{}},{"name":"stdout","text":"Evaluating 20 transactions...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Category accuracy: 55.00%\nSubcategory accuracy: 45.00%\nCombined accuracy (both correct): 45.00%\n\nSample predictions:\nTransaction: CABCHARGE AUSTRALIA DARLINGHURST...\nTrue category: Transportation\nPredicted category: Transportation\nCategory correct: True\nTrue subcategory: Taxi\nPredicted subcategory: Taxi\nSubcategory correct: True\n\nTransaction: Direct Debit Deft Payments - Deft 20603240...\nTrue category: Housing\nPredicted category: Housing\nCategory correct: True\nTrue subcategory: Rent\nPredicted subcategory: Rent\nSubcategory correct: True\n\nTransaction: CANCO SMILES PTY LTD HAWTHORN...\nTrue category: Life & Entertainment\nPredicted category: Food & Beverages\nCategory correct: False\nTrue subcategory: Health care, doctor\nPredicted subcategory: Bar, cafe, drink, snacks\nSubcategory correct: False\n\nTransaction: CHEMIST WAREHOUSE HAWTHORN VI AUSTap and Pay xx317...\nTrue category: Life & Entertainment\nPredicted category: Shopping\nCategory correct: False\nTrue subcategory: Health care, doctor\nPredicted subcategory: Drug-store, chemist\nSubcategory correct: False\n\nTransaction: AMAZON AUSYDNEY SOUTH CREDIT CARD PURCHASEAmazon B...\nTrue category: Life & Entertainment\nPredicted category: Shopping\nCategory correct: False\nTrue subcategory: Active sport, fitness\nPredicted subcategory: Leisure time\nSubcategory correct: False\n\nCategory confusion matrix:\nPredicted             Communication, PC  Financial expenses  Food & Beverages  \\\nTrue                                                                            \nCommunication, PC                     2                   0                 1   \nFinancial expenses                    0                   2                 0   \nFood & Beverages                      0                   0                 2   \nHousing                               0                   0                 0   \nIncome                                0                   0                 1   \nLife & Entertainment                  1                   0                 1   \nShopping                              0                   0                 0   \nTRANSFER                              0                   0                 0   \nTransportation                        0                   0                 0   \n\nPredicted             Housing  Life & Entertainment  Shopping  TRANSFER  \\\nTrue                                                                      \nCommunication, PC           0                     0         0         0   \nFinancial expenses          0                     1         0         0   \nFood & Beverages            0                     0         0         0   \nHousing                     2                     0         0         0   \nIncome                      0                     0         0         0   \nLife & Entertainment        0                     0         2         0   \nShopping                    0                     0         1         0   \nTRANSFER                    0                     0         0         1   \nTransportation              0                     0         0         0   \n\nPredicted             Transportation  Vehicle  \nTrue                                           \nCommunication, PC                  0        0  \nFinancial expenses                 1        0  \nFood & Beverages                   0        0  \nHousing                            0        0  \nIncome                             0        0  \nLife & Entertainment               0        1  \nShopping                           0        0  \nTRANSFER                           0        0  \nTransportation                     1        0  \n\nMost common subcategory error patterns:\n             subcategory     predicted_subcategory  count\n279      Postal services  Bar, cafe, drink, snacks      1\n223             Internet   Telephony, mobile phone      1\n164  Health care, doctor       Drug-store, chemist      1\n46         Charges, Fees     Culture, sport events      1\n162  Health care, doctor  Bar, cafe, drink, snacks      1\n\nError analysis by hierarchy:\nCorrect category but wrong subcategory: 2 cases (10.00%)\nWrong category: 9 cases (45.00%)\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_30/3292486879.py:73: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  error_counts = error_patterns.groupby(['subcategory', 'predicted_subcategory']).size().reset_index(name='count')\n","output_type":"stream"}],"execution_count":113},{"cell_type":"markdown","source":"## Train my model\nHere I train one model to learn how to set the category and train 11 models, one for each subcategory.","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport datetime\nimport time\nfrom google.api_core import retry\nfrom collections.abc import Iterable\nimport pandas as pd\nfrom tqdm.rich import tqdm as tqdmr\nimport warnings\nimport tqdm\n\n# Path for storing model IDs\nMODEL_IDS_FILE = \"/kaggle/input/training/tuned_model_ids.json\"\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\", category=tqdm.TqdmExperimentalWarning)\n\ndef prepare_training_data(df, task_type=\"subcategory\", parent_category=None):\n    \"\"\"\n    Prepare training data for fine-tuning based on task type.\n    \n    Args:\n        df: DataFrame with transaction data\n        task_type: \"category\" or \"subcategory\"\n        parent_category: Only needed for subcategory task, filters data for that category\n        \n    Returns:\n        Dictionary with examples in the format required by the API\n    \"\"\"\n    if task_type not in [\"category\", \"subcategory\"]:\n        raise ValueError(\"task_type must be 'category' or 'subcategory'\")\n    \n    # Filter by parent category if specified\n    if parent_category and task_type == \"subcategory\":\n        df = df[df['category'] == parent_category].copy()\n        \n    if len(df) == 0:\n        print(f\"Warning: No data available for {task_type}\" + \n              (f\" in category '{parent_category}'\" if parent_category else \"\"))\n        return {\"examples\": []}\n    \n    # Prepare examples\n    training_examples = []\n    for _, row in df.iterrows():\n        training_examples.append({\n            \"textInput\": str(row['note']),\n            \"output\": str(row['category' if task_type == 'category' else 'subcategory'])\n        })\n    \n    print(f\"Created {len(training_examples)} training examples for {task_type}\" + \n          (f\" in category '{parent_category}'\" if parent_category else \"\"))\n    \n    return {\"examples\": training_examples}\n\ndef get_model_ids():\n    \"\"\"Load model IDs from file or initialize empty structure\"\"\"\n    if os.path.exists(MODEL_IDS_FILE):\n        with open(MODEL_IDS_FILE, \"r\") as f:\n            return json.load(f)\n    return {\n        \"category_model\": None,\n        \"subcategory_models\": {}\n    }\n\ndef save_model_ids(model_ids):\n    \"\"\"Save model IDs to file\"\"\"\n    with open(MODEL_IDS_FILE, \"w\") as f:\n        json.dump(model_ids, f, indent=2)\n\ndef tune_model(df, task_type=\"category\", parent_category=None, \n              model_name_prefix=\"transaction-classifier\", batch_size=16, epoch_count=3):\n    \"\"\"\n    Tune a model for the given task type and save its ID.\n    \n    Args:\n        df: DataFrame with transaction data\n        task_type: \"category\" or \"subcategory\"\n        parent_category: Only needed for subcategory task, filters data for that category\n        model_name_prefix: Prefix for display name, for easier identification\n        batch_size: Batch size for tuning\n        epoch_count: Number of epochs for tuning\n        \n    Returns:\n        The model ID\n    \"\"\"\n    # Get existing model IDs\n    model_ids = get_model_ids()\n    \n    # Determine which model ID we're looking for\n    if task_type == \"category\":\n        model_id = model_ids[\"category_model\"]\n        model_key = \"category_model\"\n    else:  # subcategory\n        if parent_category is None:\n            raise ValueError(\"parent_category must be specified for subcategory task_type\")\n        model_id = model_ids[\"subcategory_models\"].get(parent_category)\n        model_key = parent_category\n    \n    # If model already exists, return it\n    if model_id:\n        print(f\"Using existing {task_type} model\" + \n              (f\" for '{parent_category}'\" if parent_category else \"\") + \n              f\": {model_id}\")\n        return model_id\n    \n    # Otherwise, check if there's a model in progress\n    queued_model = None\n    display_name = f\"{model_name_prefix}-{task_type}\" + (f\"-{parent_category.lower().replace(' ', '-')}\" if parent_category else \"\")\n    \n    # Format display name to be valid (alphanumeric chars, hyphens)\n    display_name = ''.join(c if c.isalnum() or c == '-' else '-' for c in display_name)\n    \n    print(f\"Looking for existing {task_type} tuning jobs\" + \n          (f\" for '{parent_category}'\" if parent_category else \"\"))\n    \n    # Look for existing models with this display name pattern\n    for m in reversed(client.tunings.list()):\n        if display_name.lower() in m.name.lower():\n            print(f\"Found potential model: {m.name} - state: {m.state.name}\")\n            \n            if m.state.name == 'JOB_STATE_SUCCEEDED':\n                model_id = m.name\n                print(f'Found completed model: {model_id}')\n                break\n            elif m.state.name in ['JOB_STATE_RUNNING', 'JOB_STATE_QUEUED'] and not queued_model:\n                queued_model = m.name\n                print(f'Found model in progress: {queued_model}')\n    \n    # Use queued model if none completed\n    if not model_id and queued_model:\n        model_id = queued_model\n        print(f'Using in-progress model: {model_id}')\n    \n    # Create new model if needed\n    if not model_id:\n        # Prepare training data\n        training_data = prepare_training_data(df, task_type, parent_category)\n        \n        # Don't create model if we don't have enough examples\n        if len(training_data[\"examples\"]) < 5:\n            print(f\"Skipping tuning for {task_type}\" + \n                  (f\" in category '{parent_category}'\" if parent_category else \"\") + \n                  \" due to insufficient data\")\n            return None\n        \n        # Start tuning\n        print(f\"Starting new {task_type} fine-tuning job\" + \n              (f\" for '{parent_category}'\" if parent_category else \"\"))\n        \n        try:\n            tuning_op = client.tunings.tune(\n                base_model=\"models/gemini-1.5-flash-001-tuning\",\n                training_dataset=training_data,\n                config=types.CreateTuningJobConfig(\n                    tuned_model_display_name=display_name,\n                    batch_size=batch_size,\n                    epoch_count=epoch_count,\n                ),\n            )\n            \n            model_id = tuning_op.name\n            print(f\"Fine-tuning initiated. Model ID: {model_id}\")\n            print(f\"Current status: {tuning_op.state}\")\n        except Exception as e:\n            print(f\"Error starting tuning job: {e}\")\n            return None\n    \n    # Update model IDs\n    if task_type == \"category\":\n        model_ids[\"category_model\"] = model_id\n    else:  # subcategory\n        model_ids[\"subcategory_models\"][parent_category] = model_id\n    \n    # Save updated model IDs\n    save_model_ids(model_ids)\n    \n    return model_id\n\ndef train_all_models(df_train):\n    \"\"\"\n    Train a complete hierarchical model system:\n    1. One model for category prediction\n    2. One model per category for subcategory prediction\n    \n    Args:\n        df_train: Training DataFrame\n    \n    Returns:\n        Dictionary of model IDs\n    \"\"\"\n    print(\"Starting hierarchical model training process...\")\n    \n    # Ensure we have category information\n    if 'category' not in df_train.columns:\n        raise ValueError(\"Training data must include 'category' column\")\n    \n    # 1. Train the category model\n    category_model_id = tune_model(df_train, task_type=\"category\")\n    print(f\"Category model: {category_model_id}\")\n    \n    # 2. Train category-specific subcategory models\n    unique_categories = df_train['category'].unique()\n    print(f\"Training {len(unique_categories)} category-specific models...\")\n    \n    for category in unique_categories:\n        # Check if we have enough data for this category\n        category_data = df_train[df_train['category'] == category]\n        if len(category_data) >= 10:  # Minimum threshold for training\n            subcategory_model_id = tune_model(\n                df_train, \n                task_type=\"subcategory\", \n                parent_category=category\n            )\n            print(f\"Subcategory model for '{category}': {subcategory_model_id}\")\n        else:\n            print(f\"Skipping '{category}' due to insufficient data ({len(category_data)} samples)\")\n    \n    # Return the updated model IDs\n    return get_model_ids()\n\n# Get model status information\ndef get_model_status(model_id):\n    \"\"\"Get the current status of a tuned model\"\"\"\n    if not model_id:\n        return {\"state\": \"NOT_FOUND\"}\n    \n    try:\n        model = client.tunings.get(name=model_id)\n        return {\n            \"state\": model.state.name,\n            \"success\": model.has_succeeded,\n            \"ended\": model.has_ended,\n            \"error\": model.error if hasattr(model, \"error\") else None,\n            \"create_time\": model.create_time,\n            \"progress\": model.progress if hasattr(model, \"progress\") else None\n        }\n    except Exception as e:\n        return {\"state\": \"ERROR\", \"error\": str(e)}\n\ndef get_all_model_statuses():\n    \"\"\"Get status information for all models\"\"\"\n    model_ids = get_model_ids()\n    statuses = {\n        \"category_model\": get_model_status(model_ids[\"category_model\"])\n    }\n    \n    subcategory_statuses = {}\n    for category, model_id in model_ids[\"subcategory_models\"].items():\n        subcategory_statuses[category] = get_model_status(model_id)\n    \n    statuses[\"subcategory_models\"] = subcategory_statuses\n    return statuses\n\n\ndef print_model_status(status_dict, model_type=\"Model\"):\n    \"\"\"Pretty print model status information\"\"\"\n    state = status_dict.get(\"state\", \"UNKNOWN\")\n    create_time = status_dict.get(\"create_time\")\n    progress = status_dict.get(\"progress\")\n    \n    status_text = state\n    \n    # Format creation time if available\n    time_str = \"\"\n    if create_time:\n        try:\n            # Convert to datetime if it's a string\n            if isinstance(create_time, str):\n                dt = datetime.fromisoformat(create_time.replace('Z', '+00:00'))\n            else:\n                dt = create_time\n                \n            time_str = f\", created {dt.strftime('%Y-%m-%d %H:%M:%S UTC')}\"\n        except:\n            time_str = f\", created {create_time}\"\n    \n    # Add progress if available\n    progress_str = f\", {progress}% complete\" if progress is not None else \"\"\n    \n    print(f\"{model_type} status: {status_text}{time_str}{progress_str}\")\n    \n    if status_dict.get(\"error\"):\n        print(f\"Error: {status_dict['error']}\")\n\ndef check_model_statuses():\n    \"\"\"Check and display status for all tuned models\"\"\"\n    try:\n        # Load model IDs\n        with open(\"/kaggle/input/training/tuned_model_ids.json\", \"r\") as f:\n            model_ids = json.load(f)\n        \n        # Get all statuses\n        statuses = get_all_model_statuses()\n        \n        print(\"\\n=== MODEL STATUS REPORT ===\\n\")\n        \n        # Category model status\n        category_model_id = model_ids.get(\"category_model\")\n        if category_model_id:\n            print(f\"Category Model ID: {category_model_id}\")\n            print_model_status(statuses[\"category_model\"], \"Category model\")\n        else:\n            print(\"No category model found\")\n        \n        # Subcategory models status\n        subcategory_models = model_ids.get(\"subcategory_models\", {})\n        if subcategory_models:\n            print(f\"\\nSubcategory Models ({len(subcategory_models)}):\")\n            \n            # Sort by status - succeeded first, then running, then queued\n            sorted_models = []\n            for category, model_id in subcategory_models.items():\n                status = statuses[\"subcategory_models\"].get(category, {})\n                state = status.get(\"state\", \"UNKNOWN\")\n                \n                # Define priority order for sorting\n                priority = {\n                    \"JOB_STATE_SUCCEEDED\": 0,\n                    \"JOB_STATE_RUNNING\": 1,\n                    \"JOB_STATE_QUEUED\": 2,\n                    \"ERROR\": 3,\n                    \"NOT_FOUND\": 4,\n                    \"UNKNOWN\": 5\n                }.get(state, 6)\n                \n                sorted_models.append((category, model_id, status, priority))\n            \n            # Sort by priority first, then by category name\n            sorted_models.sort(key=lambda x: (x[3], x[0]))\n            \n            for category, model_id, status, _ in sorted_models:\n                print(f\"\\n{category} Model ID: {model_id}\")\n                print_model_status(status, f\"{category} model\")\n        else:\n            print(\"\\nNo subcategory models found\")\n        \n        print(\"\\n=== END OF REPORT ===\")\n        \n        # Summary statistics\n        succeeded = sum(1 for cat, status in statuses[\"subcategory_models\"].items() \n                       if status.get(\"state\") == \"JOB_STATE_SUCCEEDED\")\n        running = sum(1 for cat, status in statuses[\"subcategory_models\"].items() \n                     if status.get(\"state\") == \"JOB_STATE_RUNNING\")\n        queued = sum(1 for cat, status in statuses[\"subcategory_models\"].items() \n                    if status.get(\"state\") == \"JOB_STATE_QUEUED\")\n        \n        total = len(subcategory_models)\n        category_status = statuses[\"category_model\"].get(\"state\", \"UNKNOWN\")\n        \n        print(f\"\\nSummary: Category model is {category_status}\")\n        print(f\"Subcategory models: {succeeded} succeeded, {running} running, {queued} queued, {total - succeeded - running - queued} other\")\n        \n    except FileNotFoundError:\n        print(\"No model IDs file found. Please run the training first.\")\n    except Exception as e:\n        print(f\"Error checking model status: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:05:02.895247Z","iopub.execute_input":"2025-04-13T22:05:02.896101Z","iopub.status.idle":"2025-04-13T22:05:02.928536Z","shell.execute_reply.started":"2025-04-13T22:05:02.896065Z","shell.execute_reply":"2025-04-13T22:05:02.927782Z"}},"outputs":[],"execution_count":114},{"cell_type":"code","source":"model_ids = train_all_models(df_train_sampled)\nprint(f\"Models are now being trained. IDs saved to {MODEL_IDS_FILE}\")","metadata":{"execution":{"iopub.status.busy":"2025-04-13T22:05:02.929616Z","iopub.execute_input":"2025-04-13T22:05:02.929907Z","iopub.status.idle":"2025-04-13T22:05:03.845265Z","shell.execute_reply.started":"2025-04-13T22:05:02.929877Z","shell.execute_reply":"2025-04-13T22:05:03.844277Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Starting hierarchical model training process...\nUsing existing category model: tunedModels/transactionclassifiercategory-976chq8zmv\nCategory model: tunedModels/transactionclassifiercategory-976chq8zmv\nTraining 11 category-specific models...\nUsing existing subcategory model for 'Life & Entertainment': tunedModels/txnsublifenentertainment-jy03vtag6m8r\nSubcategory model for 'Life & Entertainment': tunedModels/txnsublifenentertainment-jy03vtag6m8r\nUsing existing subcategory model for 'Financial expenses': tunedModels/txnsubfinancialexpenses-yc11w8ykyvvd\nSubcategory model for 'Financial expenses': tunedModels/txnsubfinancialexpenses-yc11w8ykyvvd\nUsing existing subcategory model for 'Food & Beverages': tunedModels/txnsubfoodnbeverages-ttx7p6g0cuc7\nSubcategory model for 'Food & Beverages': tunedModels/txnsubfoodnbeverages-ttx7p6g0cuc7\nUsing existing subcategory model for 'Income': tunedModels/txnsubincome-j64u1nf8izxu\nSubcategory model for 'Income': tunedModels/txnsubincome-j64u1nf8izxu\nUsing existing subcategory model for 'Shopping': tunedModels/txnsubshopping-cyzmp2twjntj\nSubcategory model for 'Shopping': tunedModels/txnsubshopping-cyzmp2twjntj\nUsing existing subcategory model for 'Housing': tunedModels/txnsubhousing-axlf21ww22py\nSubcategory model for 'Housing': tunedModels/txnsubhousing-axlf21ww22py\nUsing existing subcategory model for 'Investments': tunedModels/txnsubinvestments-adomr67a6tut\nSubcategory model for 'Investments': tunedModels/txnsubinvestments-adomr67a6tut\nUsing existing subcategory model for 'Vehicle': tunedModels/txnsubvehicle-hbzpjt22mbes\nSubcategory model for 'Vehicle': tunedModels/txnsubvehicle-hbzpjt22mbes\nUsing existing subcategory model for 'Communication, PC': tunedModels/txnsubcommunicationpc-miugmvo2f2z\nSubcategory model for 'Communication, PC': tunedModels/txnsubcommunicationpc-miugmvo2f2z\nUsing existing subcategory model for 'Transportation': tunedModels/txnsubtransportation-ask54pgcj0iv\nSubcategory model for 'Transportation': tunedModels/txnsubtransportation-ask54pgcj0iv\nLooking for existing subcategory tuning jobs for 'TRANSFER'\nCreated 50 training examples for subcategory in category 'TRANSFER'\nStarting new subcategory fine-tuning job for 'TRANSFER'\nError starting tuning job: 400 INVALID_ARGUMENT. {'error': {'code': 400, 'message': '* CreateTunedModelRequest.tuned_model.display_name: display_name must be up to 40 characters\\n', 'status': 'INVALID_ARGUMENT'}}\nSubcategory model for 'TRANSFER': None\nModels are now being trained. IDs saved to /kaggle/input/training/tuned_model_ids.json\n","output_type":"stream"}],"execution_count":115},{"cell_type":"markdown","source":"## Monitoring progress\nHere I monitor whether this model has been tuned and ready to use.","metadata":{}},{"cell_type":"code","source":"check_model_statuses()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:05:03.846646Z","iopub.execute_input":"2025-04-13T22:05:03.847033Z","iopub.status.idle":"2025-04-13T22:05:07.651962Z","shell.execute_reply.started":"2025-04-13T22:05:03.846988Z","shell.execute_reply":"2025-04-13T22:05:07.651170Z"}},"outputs":[{"name":"stdout","text":"\n=== MODEL STATUS REPORT ===\n\nCategory Model ID: tunedModels/transactionclassifiercategory-976chq8zmv\nCategory model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:04:27 UTC\n\nSubcategory Models (11):\n\nCommunication, PC Model ID: tunedModels/txnsubcommunicationpc-miugmvo2f2z\nCommunication, PC model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:50 UTC\n\nFinancial expenses Model ID: tunedModels/txnsubfinancialexpenses-yc11w8ykyvvd\nFinancial expenses model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:44 UTC\n\nFood & Beverages Model ID: tunedModels/txnsubfoodnbeverages-ttx7p6g0cuc7\nFood & Beverages model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:45 UTC\n\nHousing Model ID: tunedModels/txnsubhousing-axlf21ww22py\nHousing model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:48 UTC\n\nIncome Model ID: tunedModels/txnsubincome-j64u1nf8izxu\nIncome model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:47 UTC\n\nInvestments Model ID: tunedModels/txnsubinvestments-adomr67a6tut\nInvestments model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:49 UTC\n\nLife & Entertainment Model ID: tunedModels/txnsublifenentertainment-jy03vtag6m8r\nLife & Entertainment model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:43 UTC\n\nShopping Model ID: tunedModels/txnsubshopping-cyzmp2twjntj\nShopping model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:47 UTC\n\nTransfer Model ID: tunedModels/txnsubtransfer-u0v1si2rxove\nTransfer model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:51 UTC\n\nTransportation Model ID: tunedModels/txnsubtransportation-ask54pgcj0iv\nTransportation model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:50 UTC\n\nVehicle Model ID: tunedModels/txnsubvehicle-hbzpjt22mbes\nVehicle model status: JOB_STATE_SUCCEEDED, created 2025-04-13 14:07:49 UTC\n\n=== END OF REPORT ===\n\nSummary: Category model is JOB_STATE_SUCCEEDED\nSubcategory models: 11 succeeded, 0 running, 0 queued, 0 other\n","output_type":"stream"}],"execution_count":116},{"cell_type":"markdown","source":"## Evaluate Tuned Model\nHere I test and evaluate the performance of tuned models.","metadata":{}},{"cell_type":"code","source":"import json\nimport os\n\n# Path for storing model IDs\nMODEL_IDS_FILE = \"/kaggle/input/training/tuned_model_ids.json\"\n\ndef get_model_ids():\n    \"\"\"Load model IDs from file or initialize empty structure\"\"\"\n    if os.path.exists(MODEL_IDS_FILE):\n        with open(MODEL_IDS_FILE, \"r\") as f:\n            return json.load(f)\n    return {\n        \"category_model\": None,\n        \"subcategory_models\": {}\n    }\n\n\n# Define retry logic for API rate limits\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n@retry.Retry(predicate=is_retriable)\ndef predict_with_model(model_id, transaction_note):\n    \"\"\"Make a prediction with a specific model ID\"\"\"\n    if not model_id:\n        return \"(no model available)\"\n    \n    try:\n        response = client.models.generate_content(\n            model=model_id,\n            contents=transaction_note,\n            config=types.GenerateContentConfig(\n                temperature=0.0,  # Use deterministic output for classification\n                max_output_tokens=10  # Keep it short, we just need the category\n            )\n        )\n        \n        if response.candidates and response.candidates[0].content:\n            return response.candidates[0].content.parts[0].text.strip()\n        else:\n            return \"(error: no response)\"\n    except Exception as e:\n        return f\"(error: {str(e)})\"\n\ndef predict_transaction_category(transaction_note):\n    \"\"\"Predict just the category using the category model\"\"\"\n    model_ids = get_model_ids()\n    category_model_id = model_ids[\"category_model\"]\n    \n    if not category_model_id:\n        return \"(no category model available)\"\n    \n    return predict_with_model(category_model_id, transaction_note)\n\ndef predict_transaction_subcategory(transaction_note, category=None):\n    \"\"\"\n    Predict the subcategory using the appropriate model.\n    \n    If category is provided, uses the category-specific model.\n    If not, first predicts the category, then uses that model.\n    \"\"\"\n    model_ids = get_model_ids()\n    \n    # If category not provided, predict it first\n    if not category:\n        category = predict_transaction_category(transaction_note)\n        if category.startswith(\"(\"):  # Error or no model\n            return category\n    \n    # Use category-specific subcategory model if available\n    subcategory_model_id = model_ids[\"subcategory_models\"].get(category)\n    \n    if not subcategory_model_id:\n        return f\"(no subcategory model for '{category}')\"\n    \n    return predict_with_model(subcategory_model_id, transaction_note)\n\ndef categorize_transaction(transaction_note):\n    \"\"\"\n    Full hierarchical prediction: predict category, then subcategory.\n    \n    Returns:\n        tuple: (category, subcategory, confidence_score)\n    \"\"\"\n    # First, predict the category\n    category = predict_transaction_category(transaction_note)\n    \n    # Handle category prediction errors\n    if category.startswith(\"(error\") or category.startswith(\"(no model\"):\n        return category, \"(category prediction failed)\", 0.0\n    \n    # Next, predict the subcategory using the category-specific model\n    subcategory = predict_transaction_subcategory(transaction_note, category)\n    \n    # For now, we don't have confidence scores from the API\n    # Future enhancement: implement a confidence estimation method\n    confidence = 1.0 if not subcategory.startswith(\"(\") else 0.0\n    \n    return category, subcategory, confidence\n\ndef evaluate_models(df_test_sample, num_samples=20):\n    \"\"\"\n    Evaluate the hierarchical model system on test data.\n    \n    Args:\n        df_test_sample: Test DataFrame\n        num_samples: Number of samples to evaluate\n        \n    Returns:\n        DataFrame with evaluation results\n    \"\"\"\n    # Sample the test data\n    if len(df_test_sample) > num_samples:\n        eval_df = df_test_sample.sample(num_samples)\n    else:\n        eval_df = df_test_sample.copy()\n    \n    # Make predictions\n    results = []\n    for idx, row in tqdmr(eval_df.iterrows(), total=len(eval_df)):\n        transaction = row['note']\n        true_category = row['category']\n        true_subcategory = row['subcategory']\n        \n        # Predict\n        pred_category, pred_subcategory, confidence = categorize_transaction(transaction)\n        \n        # Store results\n        results.append({\n            'transaction': transaction,\n            'true_category': true_category,\n            'pred_category': pred_category,\n            'category_correct': true_category == pred_category,\n            'true_subcategory': true_subcategory,\n            'pred_subcategory': pred_subcategory,\n            'subcategory_correct': true_subcategory == pred_subcategory,\n            'confidence': confidence\n        })\n    \n    # Convert to DataFrame\n    results_df = pd.DataFrame(results)\n    \n    # Calculate metrics\n    category_accuracy = results_df['category_correct'].mean()\n    subcategory_accuracy = results_df['subcategory_correct'].mean()\n    \n    print(f\"Category prediction accuracy: {category_accuracy:.2%}\")\n    print(f\"Subcategory prediction accuracy: {subcategory_accuracy:.2%}\")\n    \n    # Show error analysis\n    if len(results_df[~results_df['category_correct']]) > 0:\n        print(\"\\nCategory error examples:\")\n        for idx, row in results_df[~results_df['category_correct']].head(3).iterrows():\n            print(f\"Transaction: {row['transaction'][:50]}...\")\n            print(f\"True: {row['true_category']} | Predicted: {row['pred_category']}\")\n    \n    if len(results_df[~results_df['subcategory_correct']]) > 0:\n        print(\"\\nSubcategory error examples:\")\n        for idx, row in results_df[~results_df['subcategory_correct']].head(3).iterrows():\n            print(f\"Transaction: {row['transaction'][:50]}...\")\n            print(f\"True: {row['true_subcategory']} | Predicted: {row['pred_subcategory']}\")\n    \n    return results_df\n\ndef run_evaluation(sample_size=20):\n    \"\"\"\n    Run evaluation on a sample of test transactions\n    \"\"\"\n    print(f\"Evaluating hierarchical model on {sample_size} test transactions...\\n\")\n    \n    # First check which models are ready\n    model_ids = get_model_ids()\n    statuses = get_all_model_statuses()\n    \n    # Check if category model is ready\n    category_model_ready = (statuses.get(\"category_model\", {}).get(\"state\") == \"JOB_STATE_SUCCEEDED\")\n    \n    if not category_model_ready:\n        print(\"⚠️ Category model is not ready yet. Evaluation may be limited.\")\n    \n    # Count ready subcategory models\n    ready_subcategory_models = sum(\n        1 for cat, status in statuses.get(\"subcategory_models\", {}).items() \n        if status.get(\"state\") == \"JOB_STATE_SUCCEEDED\"\n    )\n    \n    total_subcategory_models = len(model_ids.get(\"subcategory_models\", {}))\n    \n    if ready_subcategory_models < total_subcategory_models:\n        print(f\"⚠️ Only {ready_subcategory_models} of {total_subcategory_models} subcategory models are ready.\")\n        print(\"Evaluation will proceed with available models.\")\n    \n    # Sample data for evaluation\n    if len(df_test_sampled) > sample_size:\n        eval_df = df_test_sampled.sample(sample_size)\n    else:\n        eval_df = df_test_sampled.copy()\n    \n    # Now run evaluation\n    results = evaluate_models(eval_df)\n    \n    # Display confusion matrix for categories\n    print(\"\\nCategory confusion matrix:\")\n    try:\n        cat_matrix = pd.crosstab(\n            results['true_category'], \n            results['pred_category'],\n            rownames=['True'], \n            colnames=['Predicted']\n        )\n        print(cat_matrix)\n    except:\n        print(\"Unable to generate confusion matrix. Check for errors in predictions.\")\n    \n    # Display most confused subcategories\n    print(\"\\nMost commonly confused subcategories:\")\n    try:\n        subcategory_errors = results[results['subcategory_correct'] == False]\n        if len(subcategory_errors) > 0:\n            error_counts = subcategory_errors.groupby(['true_subcategory', 'pred_subcategory']).size().reset_index(name='count')\n            error_counts = error_counts.sort_values('count', ascending=False)\n            print(error_counts.head(5))\n        else:\n            print(\"No subcategory prediction errors found.\")\n    except:\n        print(\"Unable to analyze subcategory errors.\")\n    \n    return results\nresults = run_evaluation(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T22:12:48.958230Z","iopub.execute_input":"2025-04-13T22:12:48.958622Z","iopub.status.idle":"2025-04-13T22:13:27.725836Z","shell.execute_reply.started":"2025-04-13T22:12:48.958568Z","shell.execute_reply":"2025-04-13T22:13:27.724740Z"}},"outputs":[{"name":"stdout","text":"Evaluating hierarchical model on 100 test transactions...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Output()","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a1def2923f84d3386a0d19e9bad28d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Category prediction accuracy: 50.00%\nSubcategory prediction accuracy: 35.00%\n\nCategory error examples:\nTransaction: 30 NOV 19 - $150.00 REVOLUT**X337* REVOLUT.COM [Ef...\nTrue: Shopping | Predicted: Life & Entertainment\nTransaction: AMZNPRIMEAU MEMBERSHIP...\nTrue: Income | Predicted: Life & Entertainment\nTransaction: Stock...\nTrue: Investments | Predicted: Life & Entertainment\n\nSubcategory error examples:\nTransaction: Myer Pty Ltd Docklands AU...\nTrue: Home, garden | Predicted: Electronics, accessories\nTransaction: 30 NOV 19 - $150.00 REVOLUT**X337* REVOLUT.COM [Ef...\nTrue: Electronics, accessories | Predicted: Charity, gifts\nTransaction: AMZNPRIMEAU MEMBERSHIP...\nTrue: Gifts | Predicted: TV, Streaming\n\nCategory confusion matrix:\nPredicted             Communication, PC  Food & Beverages  Housing  \\\nTrue                                                                 \nCommunication, PC                     0                 0        0   \nFood & Beverages                      0                 1        0   \nHousing                               1                 0        3   \nIncome                                0                 0        0   \nInvestments                           0                 0        0   \nLife & Entertainment                  0                 0        0   \nShopping                              0                 2        0   \nVehicle                               0                 0        0   \n\nPredicted             Life & Entertainment  Shopping  Travel  \\\nTrue                                                           \nCommunication, PC                        1         0       0   \nFood & Beverages                         0         0       0   \nHousing                                  0         0       0   \nIncome                                   1         0       0   \nInvestments                              1         0       0   \nLife & Entertainment                     4         1       1   \nShopping                                 1         2       0   \nVehicle                                  0         0       0   \n\nPredicted             VehicleLife & Entertainment  \nTrue                                               \nCommunication, PC                               0  \nFood & Beverages                                0  \nHousing                                         0  \nIncome                                          0  \nInvestments                                     0  \nLife & Entertainment                            0  \nShopping                                        0  \nVehicle                                         1  \n\nMost commonly confused subcategories:\n           true_subcategory          pred_subcategory  count\n0            Charity, gifts                Gifts, joy      1\n1       Drug-store, chemist      (error: no response)      1\n2       Drug-store, chemist  Bar, cafe, drink, snacks      1\n3  Electronics, accessories            Charity, gifts      1\n4     Financial investments    Education, development      1\n","output_type":"stream"}],"execution_count":121},{"cell_type":"markdown","source":"def list_tables() -> list[str]:\n    \"\"\"Retrieve the names of all tables in the database.\"\"\"\n    # Include print logging statements so you can see when functions are being called.\n    print(' - DB CALL: list_tables()')\n\n    cursor = db_conn.cursor()\n\n    # Fetch the table names.\n    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n\n    tables = cursor.fetchall()\n    return [t[0] for t in tables]\n\n\nlist_tables()","metadata":{"execution":{"iopub.status.busy":"2025-04-13T13:39:24.135559Z","iopub.status.idle":"2025-04-13T13:39:24.135975Z","shell.execute_reply.started":"2025-04-13T13:39:24.135795Z","shell.execute_reply":"2025-04-13T13:39:24.135815Z"}}},{"cell_type":"markdown","source":"def describe_table(table_name: str) -> list[tuple[str, str]]:\n    \"\"\"Look up the table schema.\n\n    Returns:\n      List of columns, where each entry is a tuple of (column, type).\n    \"\"\"\n    print(f' - DB CALL: describe_table({table_name})')\n\n    cursor = db_conn.cursor()\n\n    cursor.execute(f\"PRAGMA table_info({table_name});\")\n\n    schema = cursor.fetchall()\n    # [column index, column name, column type, ...]\n    return [(col[1], col[2]) for col in schema]","metadata":{"execution":{"iopub.status.busy":"2025-04-13T13:39:24.138228Z","iopub.status.idle":"2025-04-13T13:39:24.138587Z","shell.execute_reply.started":"2025-04-13T13:39:24.138420Z","shell.execute_reply":"2025-04-13T13:39:24.138438Z"}}},{"cell_type":"markdown","source":"def execute_query(sql: str) -> list[list[str]]:\n    \"\"\"Execute an SQL statement, returning the results.\"\"\"\n    print(f' - DB CALL: execute_query({sql})')\n\n    cursor = db_conn.cursor()\n\n    cursor.execute(sql)\n    return cursor.fetchall()","metadata":{"execution":{"iopub.status.busy":"2025-04-13T13:39:24.140844Z","iopub.status.idle":"2025-04-13T13:39:24.141229Z","shell.execute_reply.started":"2025-04-13T13:39:24.141056Z","shell.execute_reply":"2025-04-13T13:39:24.141075Z"}}},{"cell_type":"markdown","source":"# These are the database interaction tools defined earlier\ndb_tools = [list_tables, describe_table, execute_query]\n\n# System instruction for the AI to understand what it needs to do\ninstruction = \"\"\"You are a helpful chatbot that can interact with an SQL database for financial transactions. \nYou will first use list_tables to see what tables are present, describe_table to understand the\nschema, and execute_query to issue an SQL SELECT query to retrieve all category-subcategory combinations.\"\"\"\n\n# Create the Google Genai client\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\nfrom google.api_core import retry\nimport pandas as pd\n\n# Define retry logic for API rate limits\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\n# User query to get direct category-subcategory combinations\nuser_query = \"\"\"1. Find all unique combinations of category and subcategory from the database.\n2. Execute a SQL query that joins the categories and subcategories tables.\n3. Return the full category name and full subcategory name.\n4. Format your response as simple tabular data that can be saved as CSV.\"\"\"\n\n# Function to get category-subcategory combinations with retry logic\n@retry.Retry(predicate=is_retriable)\ndef get_category_subcategory_combinations():\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=user_query,\n        config=types.GenerateContentConfig(\n            system_instruction=instruction,\n            tools=db_tools,\n        ),\n    )\n    return response.text","metadata":{"execution":{"iopub.status.busy":"2025-04-13T13:39:24.142985Z","iopub.status.idle":"2025-04-13T13:39:24.143358Z","shell.execute_reply.started":"2025-04-13T13:39:24.143188Z","shell.execute_reply":"2025-04-13T13:39:24.143207Z"}}}]}