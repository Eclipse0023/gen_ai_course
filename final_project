{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11325548,"sourceType":"datasetVersion","datasetId":7084116},{"sourceId":11335753,"sourceType":"datasetVersion","datasetId":7091033}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -qy jupyterlab  # Remove unused packages from Kaggle's base image that conflict\n!pip install -U -q \"google-genai==1.7.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:22.726330Z","iopub.execute_input":"2025-04-09T05:50:22.726760Z","iopub.status.idle":"2025-04-09T05:50:28.114868Z","shell.execute_reply.started":"2025-04-09T05:50:22.726723Z","shell.execute_reply":"2025-04-09T05:50:28.113559Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping jupyterlab as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import HTML, Markdown, display\n#https://www.kaggle.com/datasets/robbietli/transactions-20250104-test-data-csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.116589Z","iopub.execute_input":"2025-04-09T05:50:28.116968Z","iopub.status.idle":"2025-04-09T05:50:28.122080Z","shell.execute_reply.started":"2025-04-09T05:50:28.116924Z","shell.execute_reply":"2025-04-09T05:50:28.120935Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.124234Z","iopub.execute_input":"2025-04-09T05:50:28.124587Z","iopub.status.idle":"2025-04-09T05:50:28.217770Z","shell.execute_reply.started":"2025-04-09T05:50:28.124557Z","shell.execute_reply":"2025-04-09T05:50:28.216636Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"client = genai.Client(api_key=GOOGLE_API_KEY)\n\n# You can optionally set your model configuration here too\nmodel_config = types.GenerateContentConfig(\n    temperature=0.1,\n    top_p=1,\n    max_output_tokens=250,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.219220Z","iopub.execute_input":"2025-04-09T05:50:28.219585Z","iopub.status.idle":"2025-04-09T05:50:28.349631Z","shell.execute_reply.started":"2025-04-09T05:50:28.219558Z","shell.execute_reply":"2025-04-09T05:50:28.348538Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from google.api_core import retry\n\n\nis_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n\ngenai.models.Models.generate_content = retry.Retry(\n    predicate=is_retriable)(genai.models.Models.generate_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.350722Z","iopub.execute_input":"2025-04-09T05:50:28.351062Z","iopub.status.idle":"2025-04-09T05:50:28.356279Z","shell.execute_reply.started":"2025-04-09T05:50:28.351023Z","shell.execute_reply":"2025-04-09T05:50:28.355273Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"file_path = \"/kaggle/input/my-categorized-transactions/my_categorized_transactions.csv\"\nimport pandas as pd\n\n# Load your pre-categorized data\n# Assuming your file is named \"my_categorized_transactions.csv\"\ndf_training = pd.read_csv(\"my_categorized_transactions.csv\")\n\n# Create training examples in the required format\n# The format is: {\"textInput\": description, \"output\": category_with_subcategory}\ntraining_examples = []\n\nfor _, row in df_training.iterrows():\n    # Clean the description to remove sensitive information\n    description = row['note']  # The description is in the 'note' field\n    \n    # Create the correct format for the output\n    # Using \"Category:Subcategory\" format\n    output = f\"{row['category']}\"  # Since category column already has subcategory values\n    \n    # Create training example\n    training_examples.append({\n        \"textInput\": description,\n        \"output\": output\n    })\n\n# Save formatted training data\ntraining_data = {\"examples\": training_examples}\n\n# Optional - save to a JSON file for reference\nimport json\nwith open(\"training_data.json\", \"w\") as f:\n    json.dump(training_data, f)\n\nprint(f\"Prepared {len(training_examples)} training examples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.357340Z","iopub.execute_input":"2025-04-09T05:50:28.357730Z","iopub.status.idle":"2025-04-09T05:50:28.397730Z","shell.execute_reply.started":"2025-04-09T05:50:28.357693Z","shell.execute_reply":"2025-04-09T05:50:28.395993Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-5e2902a322fd>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load your pre-categorized data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Assuming your file is named \"my_categorized_transactions.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"my_categorized_transactions.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Create training examples in the required format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'my_categorized_transactions.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'my_categorized_transactions.csv'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\nfrom kaggle_secrets import UserSecretsClient\n\n# Get API key\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\nclient = genai.Client(api_key=GOOGLE_API_KEY)\n\n# Training data from step 1\ntraining_data = {\"examples\": training_examples}\n\n# Start fine-tuning\ntuning_op = client.tunings.tune(\n    base_model=\"models/gemini-1.5-flash-001-tuning\",\n    training_dataset=training_data,\n    config=types.CreateTuningJobConfig(\n        tuned_model_display_name=\"Personal Transaction Classifier\",\n        batch_size=16,\n        epoch_count=3,  # Slightly increased for better learning\n    ),\n)\n\n# Print status and save the model name for later use\nprint(f\"Fine-tuning initiated. Model ID: {tuning_op.name}\")\nprint(f\"Status: {tuning_op.state}\")\n\n# Save the model ID to a file for later reference\nwith open(\"tuned_model_id.txt\", \"w\") as f:\n    f.write(tuning_op.name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.398529Z","iopub.status.idle":"2025-04-09T05:50:28.398910Z","shell.execute_reply":"2025-04-09T05:50:28.398742Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def categorize_transaction_with_tuned_model(description):\n    \"\"\"Use fine-tuned model to categorize a transaction\"\"\"\n    \n    # Load the model ID from the file\n    with open(\"tuned_model_id.txt\", \"r\") as f:\n        model_id = f.read().strip()\n    \n    # Call the fine-tuned model directly with just the description\n    response = client.models.generate_content(\n        model=model_id,  # Your fine-tuned model ID\n        contents=[{\"text\": description}]  # Just the raw description, no prompt needed\n    )\n    \n    # Parse the response - the model outputs direct category:subcategory format\n    result_text = response.text.strip()\n    \n    # Handle the category:subcategory format\n    # The model should output in the exact format from your training data\n    return result_text\n\ndef process_transactions_with_tuned_model(descriptions, batch_size=10, show_progress=True):\n    \"\"\"Process transactions using the fine-tuned model\"\"\"\n    all_results = []\n    \n    # Setup progress bar\n    if show_progress:\n        pbar = tqdm(total=len(descriptions), desc=\"Categorizing transactions\")\n    \n    # Process in batches\n    for i in range(0, len(descriptions), batch_size):\n        batch = descriptions[i:i+batch_size]\n        batch_results = []\n        \n        print(f\"Processing batch {i//batch_size + 1} ({i} to {min(i+batch_size, len(descriptions))})...\")\n        \n        # Process each transaction in the current batch\n        for description in batch:\n            try:\n                result = categorize_transaction_with_tuned_model(description)\n                batch_results.append(result)\n                \n            except Exception as e:\n                print(f\"Error processing '{description}': {e}\")\n                batch_results.append(\"Unknown\")\n            \n            # Update progress bar\n            if show_progress:\n                pbar.update(1)\n        \n        # Add batch results to overall results\n        all_results.extend(batch_results)\n        \n        # Show sample result\n        if len(batch) > 0:\n            print(f\"Sample result - '{batch[0]}': Category='{batch_results[0]}'\")\n            print(\"-\" * 50)\n    \n    # Close progress bar\n    if show_progress:\n        pbar.close()\n    \n    return all_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.400050Z","iopub.status.idle":"2025-04-09T05:50:28.400443Z","shell.execute_reply":"2025-04-09T05:50:28.400297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_tuned_model_performance(test_df, actual_column='category', description_column='note'):\n    \"\"\"Evaluate the performance of the fine-tuned model on test data\"\"\"\n    \n    # Get predictions for all descriptions\n    descriptions = test_df[description_column].tolist()\n    predicted_categories = process_transactions_with_tuned_model(descriptions)\n    \n    # Calculate accuracy\n    test_df['predicted'] = predicted_categories\n    accuracy = (test_df[actual_column] == test_df['predicted']).mean()\n    \n    # Look at errors\n    errors = test_df[test_df[actual_column] != test_df['predicted']]\n    \n    # Focus on Transfer errors\n    false_transfers = errors[errors['predicted'] == 'Transfer']\n    transfer_as_others = errors[(errors[actual_column] == 'Transfer') & (errors['predicted'] != 'Transfer')]\n    \n    print(f\"Overall accuracy: {accuracy:.2%}\")\n    print(f\"Number of errors: {len(errors)}\")\n    print(f\"False transfers (wrongly classified as Transfer): {len(false_transfers)}\")\n    print(f\"Transfers classified as something else: {len(transfer_as_others)}\")\n    \n    # Sample of each error type\n    print(\"\\nSample false transfers:\")\n    print(false_transfers[[description_column, actual_column, 'predicted']].head())\n    \n    print(\"\\nSample transfers classified as something else:\")\n    print(transfer_as_others[[description_column, actual_column, 'predicted']].head())\n    \n    return accuracy, errors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.401768Z","iopub.status.idle":"2025-04-09T05:50:28.402078Z","shell.execute_reply":"2025-04-09T05:50:28.401951Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. First prepare your training data (run once)\n# (code from Step 1)\n\n# 2. Submit the fine-tuning job (run once)\n# (code from Step 2)\n\n# 3. Process transactions with your fine-tuned model (for ongoing use)\ndef main():\n    file_path = \"/kaggle/input/finance-test/transactions_20250104_test.csv\"\n    df = pd.read_csv(file_path)\n    \n    # Process transactions using the fine-tuned model\n    results = process_transactions_with_tuned_model(df['description'].tolist())\n    \n    # Convert results to category/subcategory format for your CSV\n    categories = []\n    subcategories = []\n    \n    for result in results:\n        # Handle different possible formats from your training data\n        if ':' in result:\n            # If model returns \"Category:Subcategory\"\n            cat, subcat = result.split(':', 1)\n            categories.append(cat)\n            subcategories.append(subcat)\n        else:\n            # If model returns just the category\n            categories.append(result)\n            subcategories.append(\"\")\n    \n    # Add results to dataframe\n    df['category'] = categories\n    df['subcategory'] = subcategories\n    \n    # Save results\n    df.to_csv(\"fine_tuned_categorized_transactions.csv\", index=False)\n    print(\"Results saved to fine_tuned_categorized_transactions.csv\")\n    \n    # Display sample\n    print(\"\\nSample of results:\")\n    print(df[['description', 'category', 'subcategory']].head(20))\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T05:50:28.403017Z","iopub.status.idle":"2025-04-09T05:50:28.403474Z","shell.execute_reply":"2025-04-09T05:50:28.403281Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"def categorise_transaction(description):\n    few_shot_prompt = f\"\"\"\n    You are an AI assistant specializing in financial transaction categorization.\n    Your task is to analyze the provided transaction description and assign it to the most appropriate category and subcategory from the predefined lists.\n\n    **Allowed Categories:**\n    [   - Food & Beverages\n       - Shopping\n       - Housing\n       - Transportation\n       - Vehicle\n       - Life & Entertainment\n       - Communication, PC\n       - Financial expenses\n       - Investments\n       - Income\n    ]\n\n    **Allowed Subcategories (grouped by category for context):**\n    [\"Food & Beverages\": [\"Bar, cafe, drink, snacks\", \"Groceries\", \"Restaurant, fast-food\"],\n       \"Shopping\": [\"Clothes & Footwear\", \"Drug-store, chemist\", \"Electronics, accessories\",\n                    \"Gifts, joy\", \"Health and beauty\", \"Home, garden\", \"Jewels, accessories\",\n                    \"Kids\", \"Leisure time\", \"Pets, animals\", \"Stationery, tools\"],\n       \"Housing\": [\"Energy, utilities\", \"Maintenance, repairs\", \"Mortgage\", \"Property insurance\",\n                   \"Rent\", \"Services\"],\n       \"Transportation\": [\"Business trips\", \"Long distance\", \"Public transport\", \"Taxi\"],\n       \"Vehicle\": [\"Fuel\", \"Leasing\", \"Parking\", \"Rentals\", \"Vehicle insurance\", \"Vehicle maintenance\"],\n       \"Life & Entertainment\": [\"Active sport, fitness\", \"Alcohol, tobacco\", \"Books, audio, subscriptions\",\n                                \"Charity, gifts\", \"Culture, sport events\", \"Education, development\",\n                                \"Health care, doctor\", \"Hobbies\", \"Holiday, trips, hotels\",\n                                \"Life events\", \"Lottery, gambling\", \"TV, Streaming\", \"Wellness, beauty\"],\n       \"Communication, PC\": [\"Internet\", \"Postal services\", \"Software, apps, games\", \"Telephony, mobile phone\"],\n       \"Financial expenses\": [\"Advisory\", \"Charges, Fees\", \"Child Support\", \"Fines\", \"Insurances\",\n                              \"Loans, interests\", \"Taxes\"],\n       \"Investments\": [\"Collections\", \"Financial investments\", \"Realty\", \"Savings\", \"Vehicles, chattels\"],\n       \"Income\": [\"Checks, coupons\", \"Child Support\", \"Dues & grants\", \"Gifts\", \"Interests, dividends\",\n                  \"Lending, renting\", \"Lottery, gambling\", \"Refunds (tax, purchase)\",\n                  \"Rental income\", \"Sale\", \"Wage, invoices\"]\n       \"Transfer\":[\"Transfer\"]\n    ]\n\n    **Instructions:**\n    [...] Respond ONLY with a JSON object [...]\n\n    **Examples:**\n\n    * **Transaction Description:** \"BP Fuel Richmond VIC\"\n        **Output:** {{\"category\": \"Transportation\", \"subcategory\": \"Fuel\"}}\n\n    * **Transaction Description:** \"Salary Deposit ACME Corp\"\n        **Output:** {{\"category\": \"Income\", \"subcategory\": \"Salary\"}}\n\n    ---\n    **Now, categorize the following transaction:**\n\n    **Description:**\n    \"{description}\"\n\n    Output\n    \"\"\"\n    return few_shot_prompt\n","metadata":{"execution":{"iopub.status.busy":"2025-04-09T03:46:19.060763Z","iopub.execute_input":"2025-04-09T03:46:19.061261Z","iopub.status.idle":"2025-04-09T03:46:19.066629Z","shell.execute_reply.started":"2025-04-09T03:46:19.061199Z","shell.execute_reply":"2025-04-09T03:46:19.065605Z"}}},{"cell_type":"code","source":"file_path = \"/kaggle/input/finance-test/transactions_20250104_test.csv\"\nimport pandas as pd\nimport json\ndf = pd.read_csv(file_path)\n\n# Import tqdm for progress bar\nfrom tqdm.notebook import tqdm\nimport time\n\ndef process_transactions_in_batches(descriptions, batch_size=5, show_progress=True):\n    all_categories = []\n    all_subcategories = []\n    \n    # Setup progress bar\n    if show_progress:\n        pbar = tqdm(total=len(descriptions), desc=\"Categorizing transactions\")\n    \n    # Process in batches\n    for i in range(0, len(descriptions), batch_size):\n        batch = descriptions[i:i+batch_size]\n        batch_categories = []\n        batch_subcategories = []\n        \n        print(f\"Processing batch {i//batch_size + 1} ({i} to {min(i+batch_size, len(descriptions))})...\")\n        \n        # Process each transaction in the current batch\n        for description in batch:\n            try:\n                # Get the formatted prompt using the function\n                prompt_text = categorise_transaction(description)\n                \n                # Start timing the API call\n                start_time = time.time()\n                \n                response = client.models.generate_content(\n                    model='gemini-2.0-flash',\n                    config=types.GenerateContentConfig(\n                        temperature=0.1,\n                        top_p=1,\n                        max_output_tokens=250,\n                    ),\n                    contents=[{\"text\": prompt_text}]  # Send the already formatted prompt\n                )\n                \n                # Calculate API call duration\n                api_time = time.time() - start_time\n                \n                # Extract category and subcategory from the JSON response\n                response_text = response.text\n                # Find JSON object using braces\n                json_start = response_text.find('{')\n                json_end = response_text.rfind('}') + 1\n                \n                if json_start >= 0 and json_end > json_start:\n                    json_str = response_text[json_start:json_end]\n                    result = json.loads(json_str)\n                    category = result.get('category', 'Unknown')\n                    subcategory = result.get('subcategory', 'Unknown')\n                else:\n                    category = 'Error'\n                    subcategory = 'Could not parse response'\n                    print(f\"Parse error for '{description}'. Response: {response_text[:100]}...\")\n                    \n            except json.JSONDecodeError as je:\n                print(f\"JSON error for '{description}': {je}\")\n                print(f\"Response text: {response_text if 'response_text' in locals() else 'No response text'}\")\n                category = 'Error'\n                subcategory = 'JSON parse error'\n            except Exception as e:\n                print(f\"Error processing '{description}': {e}\")\n                print(f\"Response was: {response.text if 'response' in locals() else 'No response'}\")\n                category = 'Error'\n                subcategory = str(e)\n            \n            batch_categories.append(category)\n            batch_subcategories.append(subcategory)\n            \n            # Update progress bar\n            if show_progress:\n                pbar.update(1)\n        \n        # Add batch results to overall results\n        all_categories.extend(batch_categories)\n        all_subcategories.extend(batch_subcategories)\n        \n        # Show detailed sample result\n        if len(batch) > 0:\n            print(f\"Sample result - '{batch[0]}': Category='{batch_categories[0]}', Subcategory='{batch_subcategories[0]}'\")\n            print(f\"API response time: {api_time:.2f} seconds\")\n            print(\"-\" * 50)\n    \n    # Close progress bar\n    if show_progress:\n        pbar.close()\n    \n    return all_categories, all_subcategories\n\n# Function to save results to CSV\ndef save_results_to_csv(df, filename=\"categorized_transactions.csv\"):\n    df.to_csv(filename, index=False)\n    print(f\"Results saved to {filename}\")\n    return filename","metadata":{"execution":{"iopub.status.busy":"2025-04-09T05:50:28.404332Z","iopub.status.idle":"2025-04-09T05:50:28.404621Z","shell.execute_reply":"2025-04-09T05:50:28.404500Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# For processing the full dataset (uncomment when ready)\nprint(\"\\nProcessing full dataset...\")\nfull_categories, full_subcategories = process_transactions_in_batches(\n    df['description'].tolist(), \n    batch_size=10,  # Increased batch size for faster processing\n    show_progress=True\n)\n\n# Add results to the main dataframe\ndf['category'] = full_categories\ndf['subcategory'] = full_subcategories\n\n# Save full results\nsave_results_to_csv(df, \"full_categorized_transactions.csv\")\n\n# Display a sample of results\nprint(\"\\nSample of Final Results:\")\nprint(df[['description', 'category', 'subcategory']].head(20))\n","metadata":{"execution":{"iopub.status.busy":"2025-04-09T03:46:19.629058Z","iopub.execute_input":"2025-04-09T03:46:19.629507Z","iopub.status.idle":"2025-04-09T03:46:55.076255Z","shell.execute_reply.started":"2025-04-09T03:46:19.629465Z","shell.execute_reply":"2025-04-09T03:46:55.075134Z"}}}]}